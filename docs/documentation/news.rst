News
==========

Follow us on `Google Group (scope-rl@googlegroups.com) <https://groups.google.com/g/scope-rl>`_!

2023
~~~~~~~~~~

**2023.12.01** Preprints of our twin papers: (1) `SCOPE-RL:  A Python Library for Offline Reinforcement Learning and Off-Policy Evaluation <https://arxiv.org/abs/2311.18206>`_ (`slides <https://speakerdeck.com/harukakiyohara_/scope-rl>`_, `日本語スライド <https://speakerdeck.com/aiueola/scope-rl-ja>`_), 
and (2) `Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation <https://arxiv.org/abs/2311.18207>`_ (`slides <https://speakerdeck.com/harukakiyohara_/towards-risk-return-assessment-of-ope>`_, `日本語スライド <https://speakerdeck.com/aiueola/towards-risk-return-assessment-of-ope-ja>`_) are now available at arXiv!

**2023.7.30** Released :class:`v0.2.1` of SCOPE-RL! This release upgrades the version of d3rlpy from  `1.1.1` to `2.0.4`.

**2023.7.21** Released :class:`v0.1.1` of SCOPE-RL! [`PyPI <https://pypi.org/project/scope-rl/>`_] [`Release Note <https://github.com/hakuhodo-technologies/scope-rl/releases>`_]