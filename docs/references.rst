References
==========

Papers
----------

.. bibliography:: refs.bib
    :style: unsrt

Projects
----------

This project and the main package of OfflineGym is strongly inspired by the following three packages.

* **Open Bandit Pipeline**  -- a pipeline implementation of OPE in contextual bandit setup: `[github] <https://github.com/st-tech/zr-obp>`_ `[documentation] <https://zr-obp.readthedocs.io/en/latest/>`_ `[paper] <https://arxiv.org/abs/2008.07146>`_.  
* **d3rlpy** -- a set of implementations of offline RL algorithms: `[github] <https://github.com/takuseno/d3rlpy>`_ `[documentation] <https://d3rlpy.readthedocs.io/en/v0.91/>`_ `[paper] <https://arxiv.org/abs/2111.03788>`_.  
* **Spinning Up** -- an educational resource for learning deepl RL: `[github] <https://github.com/openai/spinningup>`_ `[documentation] <https://spinningup.openai.com/en/latest/>`_

The sub-package, RTBGym, is inspired by the following three packages.

* **RecoGym**  -- an RL environment for recommender systems: `[github] <https://github.com/criteo-research/reco-gym>`_ `[paper] <https://arxiv.org/abs/1808.00720>`_ 
* **RecSim** -- a configurative RL environment for recommender systems: `[github] <https://github.com/google-research/recsim>`_ `[paper] <https://arxiv.org/abs/1909.04847>`_
* **FinRL** -- an RL environment for finance: `[github] <https://github.com/AI4Finance-Foundation/FinRL>`_ `[paper] <https://arxiv.org/abs/2011.09607>`_
