@article{saito2020open,
  title={Open Bandit Dataset and Pipeline: Towards Realistic and Reproducible Off-Policy Evaluation},
  author={Saito, Yuta and Aihara, Shunsuke and Matsutani, Megumi and Narita, Yusuke},
  journal={arXiv preprint arXiv:2008.07146},
  year={2020}
}

@article{seno2021d3rlpy,
  title={d3rlpy: An Offline Deep Reinforcement Learning Library},
  author={Seno, Takuma and Imai, Michita},
  journal={arXiv preprint arXiv:2111.03788},
  year={2021}
}

@inproceedings{fu2021benchmarks,
  title={Benchmarks for Deep Off-Policy Evaluation},
  author={Justin Fu and Mohammad Norouzi and Ofir Nachum and George Tucker and Ziyu Wang and Alexander Novikov and Mengjiao Yang and Michael R. Zhang and Yutian Chen and Aviral Kumar and Cosmin Paduraru and Sergey Levine and Thomas Paine},
  booktitle={Proceedings of the 9th International Conference on Learning Representations},
  year={2021}
}

@inproceedings{tang2021model,
  title={Model Selection for Offline Reinforcement Learning: Practical Considerations for Healthcare Settings},
  author={Tang, Shengpu and Wiens, Jenna},
  booktitle={Machine Learning for Healthcare Conference},
  pages={2--35},
  year={2021},
}

@inproceedings{chandak2021universal,
  title={Universal Off-Policy Evaluation},
  author={Chandak, Yash and Niekum, Scott and da Silva, Bruno and Learned-Miller, Erik and Brunskill, Emma and Thomas, Philip S},
  booktitle={Advances in Neural Information Processing Systems},
  volume={34},
  pages={27475--27490},
  year={2021}
}

@inproceedings{huang2021off,
  title={Off-Policy Risk Assessment in Contextual Bandits},
  author={Huang, Audrey and Leqi, Liu and Lipton, Zachary and Azizzadenesheli, Kamyar},
  booktitle={Advances in Neural Information Processing Systems},
  volume={34},
  pages={23714--23726},
  year={2021}
}

@inproceedings{huang2022off,
  title={Off-Policy Risk Assessment for Markov Decision Processes},
  author={Huang, Audrey and Leqi, Liu and Lipton, Zachary and Azizzadenesheli, Kamyar},
  booktitle={roceedings of the 25th International Conference on Artificial Intelligence and Statistics},
  pages={5022--5050},
  year={2022},
}

@inproceedings{van2016deep,
  title={Deep Reinforcement Learning with Double Q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={30},
  number={1},
  pages={2094-–2100},
  year={2016}
}

@inproceedings{swaminathan2015self,
  title={The Self-Normalized Estimator for Counterfactual Learning},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={Advances in Neural Information Processing Systems},
  volume={28},
  pages={3231--3239},
  year={2015}
}

@inproceedings{le2019batch,
  title={Batch policy learning under constraints},
  author={Le, Hoang and Voloshin, Cameron and Yue, Yisong},
  booktitle={Proceedings of the 36th International Conference on Machine Learning},
  pages={3703--3712},
  year={2019},
  volume={97},
  organization={PMLR}
}

@inproceedings{kumar2020conservative,
  title={Conservative Q-Learning for Offline Reinforcement Learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@inproceedings{beygelzimer2009offset,
  title={The Offset Tree for Learning with Partial Labels},
  author={Beygelzimer, Alina and Langford, John},
  booktitle={Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={129--138},
  year={2009}
}

@inproceedings{hanna2017bootstrapping,
  title={Bootstrapping with models: Confidence intervals for off-policy evaluation},
  author={Hanna, Josiah P and Stone, Peter and Niekum, Scott},
  booktitle={Proceedings of the 31st AAAI Conference on Artificial Intelligence},
  year={2017}
}

@inproceedings{strehl2010learning,
  author = {Strehl, Alex and Langford, John and Li, Lihong and Kakade, Sham M},
  booktitle = {Advances in Neural Information Processing Systems},
  pages = {2217--2225},
  title = {Learning from Logged Implicit Exploration Data},
  volume = {23},
  year = {2010}
}

@inproceedings{precup2000eligibility,
  author={Precup, Doina and Sutton, Richard S. and Singh, Satinder P.},
  title={Eligibility Traces for Off-Policy Policy Evaluation},
  year={2000},
  booktitle={Proceedings of the 17th International Conference on Machine Learning},
  pages={759–-766},
}

@inproceedings{haarnoja2018soft,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 35th International Conference on Machine Learning},
  pages={1861--1870},
  volume={80},
  year={2018},
  organization={PMLR}
}

@article{kallus2022doubly,
  title={Doubly Robust Distributionally Robust Off-Policy Evaluation and Learning},
  author={Kallus, Nathan and Mao, Xiaojie and Wang, Kaiwen and Zhou, Zhengyuan},
  journal={arXiv preprint arXiv:2202.09667},
  year={2022}
}

@inproceedings{si2020distributional,
  title={Distributional Robust Batch Contextual Bandits},
  author={Si, Nian and Zhang, Fan and Zhou, Zhengyuan and Blanchet, Jose},
  booktitle={Proceedings of the 37th International Conference on Machine Learning},
  volume={119},
  pages={8884-8894},
  year={2020}
}

@inproceedings{jiang2016doubly,
  title={Doubly Robust Off-Policy Value Evaluation for Reinforcement Learning},
  author={Jiang, Nan and Li, Lihong},
  booktitle={Proceedings of the 33rd International Conference on Machine Learning},
  volume={48},
  pages={652--661},
  year={2016},
  organization={PMLR}
}

@article{brockman2016openai,
  title={OpenAI Gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@inproceedings{thomas2016data,
  title={Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning},
  author={Thomas, Philip and Brunskill, Emma},
  booktitle={Proceedings of the 33rd International Conference on Machine Learning},
  volume={48},
  pages={2139--2148},
  year={2016},
  organization={PMLR}
}

@article{dudik2014doubly,
  title={Doubly Robust Policy Evaluation and Optimization},
  author={Dud{\'\i}k, Miroslav and Erhan, Dumitru and Langford, John and Li, Lihong},
  journal={Statistical Science},
  volume={29},
  number={4},
  pages={485--511},
  year={2014},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{kallus2020optimal,
  title={Optimal Off-Policy Evaluation from Multiple Logging Policies},
  author={Kallus, Nathan and Saito, Yuta and Uehara, Masatoshi},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  pages={5247--5256},
  year={2021},
  volume = {139}, 
  publisher={PMLR},
}

@inproceedings{kallus2018policy,
  title={Policy Evaluation and Optimization with Continuous Treatments},
  author={Kallus, Nathan and Zhou, Angela},
  booktitle={Proceedings of the 21st International Conference on Artificial Intelligence and Statistics},
  volume = {84},
  pages={1243--1251},
  year={2018},
  organization={PMLR}
}

@inproceedings{kallus2019intrinsically,
	Author = {Kallus, Nathan and Uehara, Masatoshi},
	Booktitle = {Advances in Neural Information Processing Systems},
	Title = {Intrinsically Efficient, Stable, and Bounded Off-Policy Evaluation for Reinforcement Learning},
  pages={3325--3334},
	Year = {2019}
}

@article{levine2020offline,
  title={Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{prudencio2022survey,
  title={A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems},
  author={Prudencio, Rafael Figueiredo and Maximo, Marcos ROA and Colombini, Esther Luna},
  journal={arXiv preprint arXiv:2203.01387},
  year={2022}
}

@inproceedings{wu2018budget,
  title={Budget Constrained Bidding by Model-Free Reinforcement Learning in Display Advertising},
  author={Wu, Di and Chen, Xiujun and Yang, Xun and Wang, Hao and Tan, Qing and Zhang, Xiaoxun and Xu, Jian and Gai, Kun},
  booktitle={Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
  pages={1443--1451},
  year={2018}
}

@inproceedings{zhao2018deep,
  title={Deep Reinforcement Learning for Sponsored Search Real-Time Bidding},
  author={Zhao, Jun and Qiu, Guang and Guan, Ziyu and Zhao, Wei and He, Xiaofei},
  booktitle={Proceedings of the 24th ACM SIGKDD international Conference on Knowledge Discovery and Data Mining},
  pages={1021--1030},
  year={2018}
}

@inproceedings{zhu2017gamma,
  title={A gamma-based regression for winning price estimation in real-time bidding advertising},
  author={Zhu, Wen-Yuan and Shih, Wen-Yueh and Lee, Ying-Hsuan and Peng, Wen-Chih and Huang, Jiun-Long},
  booktitle={2017 IEEE International Conference on Big Data (Big Data)},
  pages={1610--1619},
  year={2017},
}

@article{rohde2018recogym,
  title={Recogym: A Reinforcement Learning Environment for the Problem of Product Recommendation in Online Advertising},
  author={Rohde, David and Bonner, Stephen and Dunlop, Travis and Vasile, Flavian and Karatzoglou, Alexandros},
  journal={arXiv preprint arXiv:1808.00720},
  year={2018}
}

@article{ie2019recsim,
  title={Recsim: A Configurable Simulation Platform for Recommender Systems},
  author={Ie, Eugene and Hsu, Chih-wei and Mladenov, Martin and Jain, Vihan and Narvekar, Sanmit and Wang, Jing and Wu, Rui and Boutilier, Craig},
  journal={arXiv preprint arXiv:1909.04847},
  year={2019}
}

@article{liu2020finrl,
  title={FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance},
  author={Liu, Xiao-Yang and Yang, Hongyang and Chen, Qian and Zhang, Runjia and Yang, Liuqing and Xiao, Bowen and Wang, Christina Dan},
  journal={arXiv preprint arXiv:2011.09607},
  year={2020}
}
