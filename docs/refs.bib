@article{saito2021open,
  title={Open Bandit Dataset and Pipeline: Towards Realistic and Reproducible Off-Policy Evaluation},
  author={Saito, Yuta and Aihara, Shunsuke and Matsutani, Megumi and Narita, Yusuke},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}

@article{seno2021d3rlpy,
  title={d3rlpy: An Offline Deep Reinforcement Learning Library},
  author={Seno, Takuma and Imai, Michita},
  journal={arXiv preprint arXiv:2111.03788},
  year={2021}
}

@inproceedings{fu2021benchmarks,
  title={Benchmarks for Deep Off-Policy Evaluation},
  author={Justin Fu and Mohammad Norouzi and Ofir Nachum and George Tucker and Ziyu Wang and Alexander Novikov and Mengjiao Yang and Michael R. Zhang and Yutian Chen and Aviral Kumar and Cosmin Paduraru and Sergey Levine and Thomas Paine},
  booktitle={Proceedings of the 9th International Conference on Learning Representations},
  year={2021}
}

@article{paine2020hyperparameter,
  title={Hyperparameter selection for offline reinforcement learning},
  author={Paine, Tom Le and Paduraru, Cosmin and Michi, Andrea and Gulcehre, Caglar and Zolna, Konrad and Novikov, Alexander and Wang, Ziyu and de Freitas, Nando},
  journal={arXiv preprint arXiv:2007.09055},
  year={2020}
}

@article{voloshin2021empirical,
  title={Empirical Study of Off-Policy Policy Evaluation for Reinforcement Learning},
  author={Voloshin, Cameron and Le, Hoang M and Jiang, Nan and Yue, Yisong},
  journal={Advances in Neural Information Processing Systems},
  year={2019}
}

@inproceedings{tang2021model,
  title={Model Selection for Offline Reinforcement Learning: Practical Considerations for Healthcare Settings},
  author={Tang, Shengpu and Wiens, Jenna},
  booktitle={Machine Learning for Healthcare Conference},
  pages={2--35},
  year={2021},
}

@inproceedings{chandak2021universal,
  title={Universal Off-Policy Evaluation},
  author={Chandak, Yash and Niekum, Scott and da Silva, Bruno and Learned-Miller, Erik and Brunskill, Emma and Thomas, Philip S},
  booktitle={Advances in Neural Information Processing Systems},
  volume={34},
  pages={27475--27490},
  year={2021}
}

@inproceedings{huang2021off,
  title={Off-Policy Risk Assessment in Contextual Bandits},
  author={Huang, Audrey and Leqi, Liu and Lipton, Zachary and Azizzadenesheli, Kamyar},
  booktitle={Advances in Neural Information Processing Systems},
  volume={34},
  pages={23714--23726},
  year={2021}
}

@inproceedings{huang2022off,
  title={Off-Policy Risk Assessment for Markov Decision Processes},
  author={Huang, Audrey and Leqi, Liu and Lipton, Zachary and Azizzadenesheli, Kamyar},
  booktitle={roceedings of the 25th International Conference on Artificial Intelligence and Statistics},
  pages={5022--5050},
  year={2022}
}

@inproceedings{fujimoto2019off,
  title={Off-Policy Deep Reinforcement Learning without Exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={Proceedings of the 36th International Conference on Machine Learning},
  volume={97},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}

@article{van2018deep,
  title={Deep Reinforcement Learning and the Deadly Triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@article{wu2019behavior,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{fujimoto2021minimalist,
  title={A Minimalist Approach to Offline Reinforcement Learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={20132--20145},
  year={2021}
}

@article{kumar2019stabilizing,
  title={Stabilizing Off-Policy Q-learning via Bootstrapping Error Reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{ghasemipour2022so,
  title={Why So Pessimistic? Estimating Uncertainties for Offline RL through Ensembles, and Why Their Independence Matters},
  author={Ghasemipour, Seyed Kamyar Seyed and Gu, Shixiang Shane and Nachum, Ofir},
  journal={arXiv preprint arXiv:2205.13703},
  year={2022}
}

@article{kostrikov2021offline,
  title={Offline Reinforcement Learning with Implicit Q-Learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@inproceedings{van2016deep,
  title={Deep Reinforcement Learning with Double Q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={30},
  number={1},
  pages={2094-–2100},
  year={2016}
}

@inproceedings{swaminathan2015self,
  title={The Self-Normalized Estimator for Counterfactual Learning},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={Advances in Neural Information Processing Systems},
  volume={28},
  pages={3231--3239},
  year={2015}
}

@inproceedings{le2019batch,
  title={Batch policy learning under constraints},
  author={Le, Hoang and Voloshin, Cameron and Yue, Yisong},
  booktitle={Proceedings of the 36th International Conference on Machine Learning},
  pages={3703--3712},
  year={2019},
  volume={97},
  organization={PMLR}
}

@inproceedings{kumar2020conservative,
  title={Conservative Q-Learning for Offline Reinforcement Learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@article{yu2021combo,
  title={COMBO: Conservative Offline Model-Based Policy Optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={28954--28967},
  year={2021}
}

@inproceedings{beygelzimer2009offset,
  title={The Offset Tree for Learning with Partial Labels},
  author={Beygelzimer, Alina and Langford, John},
  booktitle={Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={129--138},
  year={2009}
}

@inproceedings{hanna2017bootstrapping,
  title={Bootstrapping with models: Confidence intervals for off-policy evaluation},
  author={Hanna, Josiah P and Stone, Peter and Niekum, Scott},
  booktitle={Proceedings of the 31st AAAI Conference on Artificial Intelligence},
  year={2017}
}

@inproceedings{strehl2010learning,
  author = {Strehl, Alex and Langford, John and Li, Lihong and Kakade, Sham M},
  booktitle = {Advances in Neural Information Processing Systems},
  pages = {2217--2225},
  title = {Learning from Logged Implicit Exploration Data},
  volume = {23},
  year = {2010}
}

@inproceedings{precup2000eligibility,
  author={Precup, Doina and Sutton, Richard S. and Singh, Satinder P.},
  title={Eligibility Traces for Off-Policy Policy Evaluation},
  year={2000},
  booktitle={Proceedings of the 17th International Conference on Machine Learning},
  pages={759–-766}
}

@inproceedings{haarnoja2018soft,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 35th International Conference on Machine Learning},
  pages={1861--1870},
  volume={80},
  year={2018},
  organization={PMLR}
}

@inproceedings{jiang2016doubly,
  title={Doubly Robust Off-Policy Value Evaluation for Reinforcement Learning},
  author={Jiang, Nan and Li, Lihong},
  booktitle={Proceedings of the 33rd International Conference on Machine Learning},
  volume={48},
  pages={652--661},
  year={2016},
  organization={PMLR}
}

@article{brockman2016openai,
  title={OpenAI Gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@inproceedings{thomas2015evaluation,
  title={High-confidence off-policy evaluation},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={29},
  number={1},
  year={2015}
}

@inproceedings{thomas2015improvement,
  title={High confidence policy improvement},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={2380--2388},
  year={2015},
  organization={PMLR}
}

@inproceedings{thomas2016data,
  title={Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning},
  author={Thomas, Philip and Brunskill, Emma},
  booktitle={Proceedings of the 33rd International Conference on Machine Learning},
  volume={48},
  pages={2139--2148},
  year={2016},
  organization={PMLR}
}

@article{dudik2014doubly,
  title={Doubly Robust Policy Evaluation and Optimization},
  author={Dud{\'\i}k, Miroslav and Erhan, Dumitru and Langford, John and Li, Lihong},
  journal={Statistical Science},
  volume={29},
  number={4},
  pages={485--511},
  year={2014},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{kallus2020optimal,
  title={Optimal Off-Policy Evaluation from Multiple Logging Policies},
  author={Kallus, Nathan and Saito, Yuta and Uehara, Masatoshi},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  pages={5247--5256},
  year={2021},
  volume = {139}, 
  publisher={PMLR}
}

@inproceedings{kallus2018policy,
  title={Policy Evaluation and Optimization with Continuous Treatments},
  author={Kallus, Nathan and Zhou, Angela},
  booktitle={Proceedings of the 21st International Conference on Artificial Intelligence and Statistics},
  volume = {84},
  pages={1243--1251},
  year={2018},
  organization={PMLR}
}

@inproceedings{lee2022local,
	author={Lee, Haanvid and Lee, Jongmin and Choi, Yunseon and Jeon, Wonseok and Lee, Byung-Jun and Noh, Yung-Kyun and Kim, Kee-Eung},
	booktitle={Advances in Neural Information Processing Systems},
	title={Local Metric Learning for Off-Policy Evaluation in Contextual Bandits with Continuous Actions},
  pages={xxxx--xxxx},
	year={2022}
}

@inproceedings{kurenkov2022showing,
  title={Showing Your Offline Reinforcement Learning Work: Online Evaluation Budget Matters},
  author={Kurenkov, Vladislav and Kolesnikov, Sergey},
  booktitle={Proceedings of the 39th International Conference on Machine Learning},
  pages={11729--11752},
  year={2022},
  organization={PMLR}
}

@article{yuan2021sope,
  title={SOPE: Spectrum of Off-Policy Estimators},
  author={Yuan, Christina and Chandak, Yash and Giguere, Stephen and Thomas, Philip S and Niekum, Scott},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={18958--18969},
  year={2021}
}

@article{kallus2020double,
  title={Double Reinforcement Learning for Efficient Off-Policy Evaluation in Markov Decision Processes},
  author={Kallus, Nathan and Uehara, Masatoshi},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={167},
  year={2020}
}

@inproceedings{uehara2020minimax,
  title={Minimax Weight and Q-function Learning for Off-Policy Evaluation},
  author={Uehara, Masatoshi and Huang, Jiawei and Jiang, Nan},
  booktitle={Proceedings of the 37th International Conference on Machine Learning},
  pages={9659--9668},
  year={2020},
  organization={PMLR}
}

@article{yang2020off,
  title={Off-Policy Evaluation via the Regularized Lagrangian},
  author={Yang, Mengjiao and Nachum, Ofir and Dai, Bo and Li, Lihong and Schuurmans, Dale},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6551--6561},
  year={2020}
}

@article{liu2018breaking,
  title={Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation},
  author={Liu, Qiang and Li, Lihong and Tang, Ziyang and Zhou, Dengyong},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{zhang2020gradientdice,
  title={GradientDICE: Rethinking Generalized Offline Estimation of Stationary Values},
  author={Zhang, Shangtong and Liu, Bo and Whiteson, Shimon},
  booktitle={Proceedings of the 37th International Conference on Machine Learning},
  pages={11194--11203},
  year={2020},
  organization={PMLR}
}

@article{zhang2020gendice,
  title={GenDICE: Generalized Offline Estimation of Stationary Values},
  author={Zhang, Ruiyi and Dai, Bo and Li, Lihong and Schuurmans, Dale},
  journal={Proceedings of the 8th International Conference on Learning Representations},
  year={2020}
}

@article{nachum2019algaedice,
  title={AlgaeDICE: Policy Gradient from Arbitrary Experience},
  author={Nachum, Ofir and Dai, Bo and Kostrikov, Ilya and Chow, Yinlam and Li, Lihong and Schuurmans, Dale},
  journal={arXiv preprint arXiv:1912.02074},
  year={2019}
}

@article{nachum2019dualdice,
  title={DualDICE: Behavior-Agnostic Estimation of Discounted Stationary Distribution Corrections},
  author={Nachum, Ofir and Chow, Yinlam and Dai, Bo and Li, Lihong},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{kallus2019intrinsically,
	author={Kallus, Nathan and Uehara, Masatoshi},
	booktitle={Advances in Neural Information Processing Systems},
	title={Intrinsically Efficient, Stable, and Bounded Off-Policy Evaluation for Reinforcement Learning},
  pages={3325--3334},
	year={2019}
}

@article{levine2020offline,
  title={Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{prudencio2022survey,
  title={A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems},
  author={Prudencio, Rafael Figueiredo and Maximo, Marcos ROA and Colombini, Esther Luna},
  journal={arXiv preprint arXiv:2203.01387},
  year={2022}
}

@article{uehara2022review,
  title={A Review of Off-Policy Evaluation in Reinforcement Learning},
  author={Uehara, Masatoshi and Shi, Chengchun and Kallus, Nathan},
  journal={arXiv preprint arXiv:2212.06355},
  year={2022}
}

@article{matsushima2020deployment,
  title={Deployment-Efficient Reinforcement Learning via Model-based Offline Optimization},
  author={Matsushima, Tatsuya and Furuta, Hiroki and Matsuo, Yutaka and Nachum, Ofir and Gu, Shixiang},
  journal={Proceedings of the 9th International Conference on Learning Representations},
  year={2021}
}

@inproceedings{wu2018budget,
  title={Budget Constrained Bidding by Model-Free Reinforcement Learning in Display Advertising},
  author={Wu, Di and Chen, Xiujun and Yang, Xun and Wang, Hao and Tan, Qing and Zhang, Xiaoxun and Xu, Jian and Gai, Kun},
  booktitle={Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
  pages={1443--1451},
  year={2018}
}

@inproceedings{zhao2018deep,
  title={Deep Reinforcement Learning for Sponsored Search Real-Time Bidding},
  author={Zhao, Jun and Qiu, Guang and Guan, Ziyu and Zhao, Wei and He, Xiaofei},
  booktitle={Proceedings of the 24th ACM SIGKDD international Conference on Knowledge Discovery and Data Mining},
  pages={1021--1030},
  year={2018}
}

@inproceedings{zhu2017gamma,
  title={A gamma-based regression for winning price estimation in real-time bidding advertising},
  author={Zhu, Wen-Yuan and Shih, Wen-Yueh and Lee, Ying-Hsuan and Peng, Wen-Chih and Huang, Jiun-Long},
  booktitle={2017 IEEE International Conference on Big Data},
  pages={1610--1619},
  year={2017},
}

@Inproceedings{jeunen2022learning,
 author={Olivier Jeunen and Sean Murphy and Ben Allison},
 title={Learning to bid with AuctionGym},
 year={2022},
 url={https://www.amazon.science/publications/learning-to-bid-with-auctiongym},
 booktitle={KDD 2022 Workshop on Artificial Intelligence for Computational Advertising (AdKDD)},
}

@article{rohde2018recogym,
  title={Recogym: A Reinforcement Learning Environment for the Problem of Product Recommendation in Online Advertising},
  author={Rohde, David and Bonner, Stephen and Dunlop, Travis and Vasile, Flavian and Karatzoglou, Alexandros},
  journal={arXiv preprint arXiv:1808.00720},
  year={2018}
}

@article{ie2019recsim,
  title={Recsim: A Configurable Simulation Platform for Recommender Systems},
  author={Ie, Eugene and Hsu, Chih-wei and Mladenov, Martin and Jain, Vihan and Narvekar, Sanmit and Wang, Jing and Wu, Rui and Boutilier, Craig},
  journal={arXiv preprint arXiv:1909.04847},
  year={2019}
}

@article{liu2020finrl,
  title={FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance},
  author={Liu, Xiao-Yang and Yang, Hongyang and Chen, Qian and Zhang, Runjia and Yang, Liuqing and Xiao, Bowen and Wang, Christina Dan},
  journal={arXiv preprint arXiv:2011.09607},
  year={2020}
}

@inproceedings{dean2022preference,
  title={Preference Dynamics under Personalized Recommendations},
  author={Dean, Sarah and Morgenstern, Jamie},
  booktitle={Proceedings of the 23rd ACM Conference on Economics and Computation},
  pages={795--816},
  year={2022}
}

@article{kakade2001natural,
  title={A Natural Policy Gradient},
  author={Kakade, Sham M},
  journal={Advances in Neural Information Processing Systems},
  volume={14},
  year={2001}
}

@inproceedings{silver2014deterministic,
  title={Deterministic Policy Gradient Algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={Proceedings of the 31th International Conference on Machine Learning},
  pages={387--395},
  year={2014},
  organization={PMLR}
}

@article{watkins1992q,
  title={Q-Learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@article{mnih2013playing,
  title={Playing Atari with Deep Reinforcement Learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{konda1999actor,
  title={Actor-Critic Algorithms},
  author={Konda, Vijay and Tsitsiklis, John},
  journal={Advances in Neural Information Processing Systems},
  volume={12},
  year={1999}
}

@inproceedings{degris2012off,
  title={Off-Policy Actor-Critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  booktitle={Proceedings of the 29th International Coference on Machine Learning},
  pages={179--186},
  year={2012}
}
