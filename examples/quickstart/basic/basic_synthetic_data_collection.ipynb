{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart Example with Basic Synthetic Simulation and Dataset (Data Collection)\n",
    "This notebook provides an example of visualizing the logged dataset collected on an basic environment.\n",
    "\n",
    "This example on consists of the following 3 cases:\n",
    "1. Discrete Action Case\n",
    "2. Continuous Action Case\n",
    "3. Collecting Logged Datasets with Multiple Behavior Policies and Random Seeds\n",
    "\n",
    "\\* This library uses [d3rlpy](https://github.com/takuseno/d3rlpy)'s algorithm implementations.  \n",
    "\\* Also, our data collection module is highly inspired by [Open Bandit Pipeline](https://github.com/st-tech/zr-obp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# delete later\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete later\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SCOPE-RL modules\n",
    "import scope_rl\n",
    "from basicgym import BasicEnv\n",
    "from scope_rl.dataset import SyntheticDataset\n",
    "from scope_rl.policy import OnlineHead\n",
    "from scope_rl.ope.online import (\n",
    "    calc_on_policy_policy_value,\n",
    "    visualize_on_policy_policy_value,\n",
    ")\n",
    "\n",
    "# import d3rlpy algorithms\n",
    "from d3rlpy.algos import DiscreteRandomPolicy\n",
    "from d3rlpy.algos import RandomPolicy as ContinuousRandomPolicy\n",
    "from d3rlpy.preprocessing import MinMaxActionScaler\n",
    "\n",
    "# import from other libraries\n",
    "import gym\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Union, Optional\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0\n"
     ]
    }
   ],
   "source": [
    "# version\n",
    "print(scope_rl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random state\n",
    "random_state = 12345\n",
    "random_ = check_random_state(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Description of Synthetic Basic Simulation Environment\n",
    "To begin with, we briefly describe the basic usage of the environment.\n",
    "\n",
    "#### RL setup for Synthetic\n",
    "In Synthetic , the objective of the RL agent is to maximize reward\n",
    "\n",
    "We often formulate this synthetic  problem as the following (Partially Observable) Markov Decision Process ((PO)MDP):\n",
    "- `state`: State observation, which may be noisy in POMDPs.\n",
    "- `action`:  Indicating the action to presented by the RL agent.\n",
    "- `reward`: Reward observation.\n",
    "\n",
    "Let's see how it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup environment\n",
    "env = BasicEnv(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a random agent\n",
    "agent = OnlineHead(\n",
    "    ContinuousRandomPolicy(\n",
    "        action_scaler=MinMaxActionScaler(\n",
    "            minimum=env.action_space.low,  # minimum value that policy can take\n",
    "            maximum=env.action_space.high,  # maximum value that policy can take\n",
    "        )\n",
    "    ),\n",
    "    name=\"random\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interact agent with the environment\n",
    "# only 6 lines are needed for RL interaction\n",
    "for episode in range(10):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = agent.predict_online(obs)\n",
    "        obs, reward, done, truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "[-0.37164978 -0.49943402  0.36963097 -0.28399277 -0.62862005]\n"
     ]
    }
   ],
   "source": [
    "# state \n",
    "print(obs.shape)\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's visualize the transition of the reward\n",
    "# our goal is to obtain a policy (or an agent) that maximizes the reward\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "reward_list = []\n",
    "\n",
    "while not done:\n",
    "    action = agent.sample_action_online(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    reward_list.append(reward)\n",
    "\n",
    "# plot\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(reward_list[:-1], label='reward', color='tab:orange')\n",
    "ax1.set_xlabel('timestep')\n",
    "ax1.set_ylabel('reward')\n",
    "ax1.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more about the environmental configuration , please refer to [examples/quickstart/basic/basic_synthetic_customize_env.ipynb](https://github.com/hakuhodo-technologies/scope-rl/blob/main/examples/quickstart/basic/basic_synthetic_customize_env.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Discrete Action Case\n",
    "Here, we present how to collect logged data by a behavior policy in the case of discrete action.\n",
    "\n",
    "The procedure requires two steps:\n",
    "\n",
    "1. Learn a base deterministic policy\n",
    "2. Convert the deterministic policy into a stochastic policy.\n",
    "\n",
    "Below, we first learn a deterministic policy using [d3rlpy](https://github.com/takuseno/d3rlpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized environment for discrete action\n",
    "env = gym.make(\"BasicEnv-discrete-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for api compatibility to d3rlpy\n",
    "from scope_rl.utils import OldGymAPIWrapper\n",
    "env_ = OldGymAPIWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn a base deterministic policy for data collection\n",
    "from d3rlpy.algos import DoubleDQN\n",
    "from d3rlpy.models.encoders import VectorEncoderFactory\n",
    "from d3rlpy.models.q_functions import MeanQFunctionFactory\n",
    "from d3rlpy.online.buffers import ReplayBuffer\n",
    "from d3rlpy.online.explorers import LinearDecayEpsilonGreedy\n",
    "\n",
    "# model\n",
    "ddqn = DoubleDQN(\n",
    "    encoder_factory=VectorEncoderFactory(hidden_units=[30, 30]),\n",
    "    q_func_factory=MeanQFunctionFactory(),\n",
    "    target_update_interval=100,\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    ")\n",
    "# replay buffer\n",
    "buffer = ReplayBuffer(\n",
    "    maxlen=10000,\n",
    "    env=env_,\n",
    ")\n",
    "# explorers\n",
    "explorer = LinearDecayEpsilonGreedy(\n",
    "    start_epsilon=1.0,\n",
    "    end_epsilon=0.1,\n",
    "    duration=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "# skip if there is a pre-trained model\n",
    "ddqn.fit_online(\n",
    "    env_,\n",
    "    buffer,\n",
    "    explorer=explorer,\n",
    "    eval_env=env_,\n",
    "    n_steps=100000,\n",
    "    n_steps_per_epoch=1000,\n",
    "    update_start_step=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "ddqn.save_model(\"d3rlpy_logs/ddqn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-19 16:55.16 [warning  ] Parameters will be reinitialized.\n"
     ]
    }
   ],
   "source": [
    "# reload model\n",
    "ddqn.build_with_env(env)\n",
    "ddqn.load_model(\"d3rlpy_logs/ddqn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Epsilon-Greedy behavior policy\n",
    "\n",
    "Let's now convert the deterministic policy (i.e., ddqn policy) into a stochastic behavior policy.\n",
    "\n",
    "We use epsilon-greedy policy to collect logged data using `DiscreteEpsilonGreedyHead`, where the behavior policy greedily takes an action chosen by the deterministic policy with probability $1 - \\epsilon$ and takes an action randomly with probability $\\epsilon$ as follows.\n",
    "\n",
    "$$\\pi(a | s) := (1 - \\epsilon) * \\pi_{\\mathrm{det}}(a | s) + \\epsilon / |\\mathcal{A}|,$$\n",
    "\n",
    "where $a \\in \\mathcal{A}$ is an action, $s \\in \\mathcal{S}$ is a state, and $\\pi$ is a stochastic policy defined with the (deterministic) behavior policy $\\pi_{\\mathrm{det}}$.\n",
    "\n",
    "`SyntheticDataset` has the following arguments:\n",
    "- `env`: Basic synthetic environment for RL defined in the previous section.\n",
    "- `max_episode_steps`: Maximum number of timesteps in an episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the base ddqn policy into a stochastic data collection policy\n",
    "from scope_rl.policy import DiscreteEpsilonGreedyHead\n",
    "\n",
    "behavior_policy = DiscreteEpsilonGreedyHead(\n",
    "    ddqn, \n",
    "    n_actions=env.action_space.n,\n",
    "    epsilon=0.3,  # probability of taking random action\n",
    "    name=\"ddqn_epsilon_0.3\",\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b993cca66d44eb89092be127186824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_trajectories]:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# collect data\n",
    "dataset = SyntheticDataset(\n",
    "    env=env,\n",
    "    max_episode_steps=env.step_per_episode,\n",
    ")\n",
    "logged_dataset = dataset.obtain_episodes(\n",
    "    behavior_policies=behavior_policy,\n",
    "    n_trajectories=10000, \n",
    "    obtain_info=False,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': 100000,\n",
       " 'n_trajectories': 10000,\n",
       " 'step_per_trajectory': 10,\n",
       " 'action_type': 'discrete',\n",
       " 'n_actions': 10,\n",
       " 'action_dim': None,\n",
       " 'action_meaning': None,\n",
       " 'action_keys': None,\n",
       " 'state_dim': 5,\n",
       " 'state_keys': None,\n",
       " 'state': array([[ 0.46692103, -0.60091272,  0.12748286,  0.10612129,  0.62719618],\n",
       "        [ 0.00305434,  0.25886564,  0.94683458, -0.18441597, -0.04974207],\n",
       "        [ 0.09209668,  0.18060315, -0.96557628, -0.16297735,  0.00123719],\n",
       "        ...,\n",
       "        [-0.08604248, -0.06294277,  0.46005661, -0.31068976,  0.82489678],\n",
       "        [ 0.7231203 ,  0.3276454 ,  0.26169129, -0.20740293,  0.5081803 ],\n",
       "        [-0.13514496,  0.03110442,  0.26689395, -0.95193514,  0.0579264 ]]),\n",
       " 'action': array([6, 1, 5, ..., 8, 6, 5]),\n",
       " 'reward': array([ 0.85571015, -0.27916946,  0.43932507, ...,  0.09842358,\n",
       "         0.83497698,  0.65557526]),\n",
       " 'done': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'terminal': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'info': {},\n",
       " 'pscore': array([0.73, 0.03, 0.73, ..., 0.03, 0.73, 0.03]),\n",
       " 'behavior_policy': 'ddqn_epsilon_0.3',\n",
       " 'dataset_id': 0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Softmax behavior policy\n",
    "We can also use `DiscreteSoftmaxHead` to derive a stochastic behavior policy.\n",
    "\n",
    "This algorithm uses Q function of the original algorithm, which estimates the value of a given context and action pair (i.e., $(s, a)$) as $Q(s, a)$. \\\n",
    "Specifically, the behavior policy chooses actions stochastically as:\n",
    "\n",
    "$$\\pi(a \\mid s) = \\frac{\\exp(Q(s, a) / \\tau)}{\\sum_{a' \\in A} \\exp(Q(s, a') / \\tau)},$$\n",
    "\n",
    "where $A$ indicates the set discrete actions and $\\tau$ is an inverse temperature parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert base ddqn policy into a stochastic data collection policy\n",
    "from scope_rl.policy import DiscreteSoftmaxHead\n",
    "\n",
    "behavior_policy = DiscreteSoftmaxHead(\n",
    "    ddqn, \n",
    "    n_actions=env.action_space.n,\n",
    "    tau=1.0,  # temperature parameter\n",
    "    name=\"ddqn_softmax_tau_1.0\",\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54d8eece4604771968a56135a848a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_trajectories]:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# collect data\n",
    "dataset = SyntheticDataset(\n",
    "    env=env,\n",
    "    max_episode_steps=env.step_per_episode,\n",
    ")\n",
    "logged_dataset = dataset.obtain_episodes(\n",
    "    behavior_policies=behavior_policy, \n",
    "    n_trajectories=10000, \n",
    "    obtain_info=False,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': 100000,\n",
       " 'n_trajectories': 10000,\n",
       " 'step_per_trajectory': 10,\n",
       " 'action_type': 'discrete',\n",
       " 'n_actions': 10,\n",
       " 'action_dim': None,\n",
       " 'action_meaning': None,\n",
       " 'action_keys': None,\n",
       " 'state_dim': 5,\n",
       " 'state_keys': None,\n",
       " 'state': array([[ 0.46692103, -0.60091272,  0.12748286,  0.10612129,  0.62719618],\n",
       "        [ 0.00305434,  0.25886564,  0.94683458, -0.18441597, -0.04974207],\n",
       "        [-0.04232595,  0.00530112, -0.23147397, -0.24222478,  0.94123715],\n",
       "        ...,\n",
       "        [ 0.33303925, -0.12147387, -0.53166742, -0.44979933,  0.62397057],\n",
       "        [-0.07047588, -0.45761772,  0.794374  , -0.38997429,  0.05009166],\n",
       "        [-0.10470584, -0.07035717,  0.43358778, -0.35178959,  0.8199587 ]]),\n",
       " 'action': array([6, 8, 6, ..., 5, 6, 2]),\n",
       " 'reward': array([ 0.85571015, -0.38244575,  0.92561678, ...,  0.59526105,\n",
       "         0.89869983,  0.53432782]),\n",
       " 'done': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'terminal': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'info': {},\n",
       " 'pscore': array([0.16227005, 0.09263128, 0.11330675, ..., 0.13710368, 0.15752947,\n",
       "        0.12084852]),\n",
       " 'behavior_policy': 'ddqn_softmax_tau_1.0',\n",
       " 'dataset_id': 0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For offline RL and OPE procedures, please refer to [examples/quickstart/basic/basic_synthetic_discrete_basic.ipynb](https://github.com/negocia-inc/scope_rl/blob/master/examples/quickstart/basic/basic_synthetic_discrete_basic.ipynb).\n",
    "\n",
    "For more advanced topic in OPE and OPS, please refer to [examples/quickstart/basic/basic_synthetic_discrete_advanced.ipynb](https://github.com/negocia-inc/scope_rl/blob/ope/examples/quickstart/basic/basic_synthetic_discrete_advanced.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Continuous Action Space\n",
    "We also describe the case where a continuous behavior policy is used. \\\n",
    "Here, we first learn a base deterministic policy in a similar manner with the discrete action case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized environment for continuous action\n",
    "env = gym.make(\"BasicEnv-continuous-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for api compatibility to d3rlpy\n",
    "env_ = OldGymAPIWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn base deterministic policy for data collection\n",
    "from d3rlpy.algos import SAC\n",
    "from d3rlpy.models.encoders import VectorEncoderFactory\n",
    "from d3rlpy.models.q_functions import MeanQFunctionFactory\n",
    "from d3rlpy.online.buffers import ReplayBuffer\n",
    "\n",
    "# model\n",
    "sac = SAC(\n",
    "    actor_encoder_factory=VectorEncoderFactory(hidden_units=[30, 30]),\n",
    "    critic_encoder_factory=VectorEncoderFactory(hidden_units=[30, 30]),\n",
    "    q_func_factory=MeanQFunctionFactory(),\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    "    action_scaler=MinMaxActionScaler(\n",
    "        minimum=env.action_space.low,   # 0.1\n",
    "        maximum=env.action_space.high,  # 10\n",
    "    ),\n",
    ")\n",
    "# setup replay buffer\n",
    "buffer = ReplayBuffer(\n",
    "    maxlen=10000,\n",
    "    env=env,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "# skip if there is a pre-trained model\n",
    "sac.fit_online(\n",
    "    env_,\n",
    "    buffer,\n",
    "    eval_env=env_,\n",
    "    n_steps=100000,\n",
    "    n_steps_per_epoch=1000,\n",
    "    update_start_step=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "sac.save_model(\"d3rlpy_logs/sac.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-19 17:01.04 [warning  ] Parameters will be reinitialized.\n"
     ]
    }
   ],
   "source": [
    "# reload model\n",
    "sac.build_with_env(env)\n",
    "sac.load_model(\"d3rlpy_logs/sac.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Gaussian behavior policy\n",
    "\n",
    "Then, we convert a deterministic policy (i.e., greedy action choice of sac policy) into a stochastic policy. \n",
    "\n",
    "As the action space of `BasicEnv` is bounded, we use `ContinuousTruncatedGaussianHead`. \\\n",
    "Given the deterministic action $\\pi(s)$, this behavior policy samples actions from a truncated gaussian distribution as:\n",
    "\n",
    "$$a \\sim Truncnorm(\\pi(s), \\sigma),$$\n",
    "\n",
    "where $\\sigma$ indicates the noise level. \n",
    "\n",
    "Note that, when action space is not bounded, we can use `ContinuousGaussianHead` in a similar manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert base ddqn policy into a stochastic data collection policy\n",
    "from scope_rl.policy import ContinuousTruncatedGaussianHead\n",
    "\n",
    "behavior_policy = ContinuousTruncatedGaussianHead(\n",
    "    sac, \n",
    "    minimum=env.action_space.low,  # lower bound of the action space\n",
    "    maximum=env.action_space.high,  # upper bound of the action space\n",
    "    sigma=np.array([1.0]),  # noise level of a gaussian distribution\n",
    "    name=\"sac_sigma_1.0\",\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282825d83f9e435d96ffc4c6d8c67847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_trajectories]:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# collect data\n",
    "dataset = SyntheticDataset(\n",
    "    env=env,\n",
    "    max_episode_steps=env.step_per_episode,\n",
    ")\n",
    "logged_dataset = dataset.obtain_episodes(\n",
    "    behavior_policies=behavior_policy,\n",
    "    n_trajectories=10000, \n",
    "    obtain_info=False,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': 100000,\n",
       " 'n_trajectories': 10000,\n",
       " 'step_per_trajectory': 10,\n",
       " 'action_type': 'continuous',\n",
       " 'n_actions': None,\n",
       " 'action_dim': 3,\n",
       " 'action_meaning': None,\n",
       " 'action_keys': None,\n",
       " 'state_dim': 5,\n",
       " 'state_keys': None,\n",
       " 'state': array([[ 0.46692103, -0.60091272,  0.12748286,  0.10612129,  0.62719618],\n",
       "        [ 0.23609089, -0.50355012,  0.42207593, -0.65038681,  0.2992445 ],\n",
       "        [ 0.0601901 ,  0.45938391,  0.7251643 ,  0.10180222,  0.49911584],\n",
       "        ...,\n",
       "        [-0.40770033, -0.17992142, -0.70017998, -0.00489399,  0.55779277],\n",
       "        [ 0.38460862,  0.36605222, -0.43847431,  0.30099484, -0.65971537],\n",
       "        [-0.34752225, -0.56691129, -0.63707318, -0.23699787, -0.30953134]]),\n",
       " 'action': array([[ 0.49497776, -0.80337565,  0.89943277],\n",
       "        [ 0.41315293,  0.1117985 , -0.44134898],\n",
       "        [ 0.68023601,  0.50271535, -0.10667011],\n",
       "        ...,\n",
       "        [-0.59465215,  0.92170738,  0.13497234],\n",
       "        [-0.28329238, -0.23372348,  0.59522857],\n",
       "        [-0.06848986,  0.78710364, -0.29546909]]),\n",
       " 'reward': array([ 0.53529708,  0.26419521,  0.51816541, ...,  0.0779796 ,\n",
       "        -0.34357986, -0.19074574]),\n",
       " 'done': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'terminal': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'info': {},\n",
       " 'pscore': array([[0.09885379, 0.09885379, 0.09885379],\n",
       "        [0.25108443, 0.25108443, 0.25108443],\n",
       "        [0.27544345, 0.27544345, 0.27544345],\n",
       "        ...,\n",
       "        [0.04859119, 0.04859119, 0.04859119],\n",
       "        [0.11385128, 0.11385128, 0.11385128],\n",
       "        [0.08344385, 0.08344385, 0.08344385]]),\n",
       " 'behavior_policy': 'sac_sigma_1.0',\n",
       " 'dataset_id': 0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Collecting Logged Datasets with Multiple Behavior Policies and Random Seeds\n",
    "Finally, we show how to collect logged data by several behavior policies and random seeds.\n",
    "\n",
    "We show the example in the discrete action case, but the continuous action case can also be handled in a simmilar manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized environment for discrete action\n",
    "env = gym.make(\"BasicEnv-discrete-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define several behavior policies\n",
    "behavior_policy_01 = DiscreteEpsilonGreedyHead(\n",
    "    ddqn, \n",
    "    n_actions=env.action_space.n,\n",
    "    epsilon=0.1,  # probability of taking random action\n",
    "    name=\"ddqn_eps_0.1\",\n",
    "    random_state=random_state,\n",
    ")\n",
    "behavior_policy_03 = DiscreteEpsilonGreedyHead(\n",
    "    ddqn, \n",
    "    n_actions=env.action_space.n,\n",
    "    epsilon=0.3,  # probability of taking random action\n",
    "    name=\"ddqn_eps_0.3\",\n",
    "    random_state=random_state,\n",
    ")\n",
    "behavior_policy_05 = DiscreteEpsilonGreedyHead(\n",
    "    ddqn, \n",
    "    n_actions=env.action_space.n,\n",
    "    epsilon=0.5,  # probability of taking random action\n",
    "    name=\"ddqn_eps_0.5\",\n",
    "    random_state=random_state,\n",
    ")\n",
    "behavior_policy_07 = DiscreteEpsilonGreedyHead(\n",
    "    ddqn, \n",
    "    n_actions=env.action_space.n,\n",
    "    epsilon=0.7,  # probability of taking random action\n",
    "    name=\"ddqn_eps_0.7\",\n",
    "    random_state=random_state,\n",
    ")\n",
    "behavior_policies = [behavior_policy_01, behavior_policy_03, behavior_policy_05, behavior_policy_07]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dataset class\n",
    "dataset = SyntheticDataset(\n",
    "    env=env,\n",
    "    max_episode_steps=env.step_per_episode,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7578d0e2d93d4f41a6041278a6327361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_datasets: behavior_policy]:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e6c372b9774567a24d01fa1d6496ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_datasets: dataset_id]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a657e26cf6847dab5e6f3fce4b00c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_trajectories]:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb745c9a82d455393628b27ed3a3333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_trajectories]:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fe38d8352842c4a23ab136cf512b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_datasets: dataset_id]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648d43a457d047b095ce383be440aa66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_trajectories]:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f957ce75a88444619b166deda6638b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_trajectories]:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eab22813afc4eac8a4c160ea0477dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_datasets: dataset_id]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767fcb95767747acbc059c20a2e469fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_trajectories]:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6488c8d7ee4f739f91d382219c7255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_trajectories]:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152e105c42514eb69a4b318c27bd82d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_datasets: dataset_id]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d0fb83eeb6479f8af73bfb2f8860e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_trajectories]:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2028cf651154071ad15dd44abbb86d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_trajectories]:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logged_datasets = dataset.obtain_episodes(\n",
    "    behavior_policies=behavior_policies,\n",
    "    n_datasets=2,  # number of random states\n",
    "    n_trajectories=10000, \n",
    "    obtain_info=False,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': 100000,\n",
       " 'n_trajectories': 10000,\n",
       " 'step_per_trajectory': 10,\n",
       " 'action_type': 'discrete',\n",
       " 'n_actions': 10,\n",
       " 'action_dim': None,\n",
       " 'action_meaning': None,\n",
       " 'action_keys': None,\n",
       " 'state_dim': 5,\n",
       " 'state_keys': None,\n",
       " 'state': array([[ 0.46692103, -0.60091272,  0.12748286,  0.10612129,  0.62719618],\n",
       "        [ 0.00305434,  0.25886564,  0.94683458, -0.18441597, -0.04974207],\n",
       "        [-0.13005656, -0.04117723,  0.18071338, -0.53347445,  0.81494626],\n",
       "        ...,\n",
       "        [-0.08940592, -0.45477914,  0.78416664, -0.39813098,  0.10842927],\n",
       "        [-0.00321797, -0.09604929,  0.03883138,  0.035452  ,  0.99398162],\n",
       "        [ 0.65571773,  0.04974576, -0.48633835, -0.55171117,  0.16324647]]),\n",
       " 'action': array([6, 6, 9, ..., 8, 9, 5]),\n",
       " 'reward': array([ 0.85571015,  0.80607969,  0.94343082, ..., -0.36078503,\n",
       "         1.00888756,  0.46196748]),\n",
       " 'done': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'terminal': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'info': {},\n",
       " 'pscore': array([0.91, 0.91, 0.91, ..., 0.01, 0.91, 0.91]),\n",
       " 'behavior_policy': 'ddqn_eps_0.1',\n",
       " 'dataset_id': 0}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_dataset = logged_datasets.get(behavior_policy_name=behavior_policies[0].name, dataset_id=0)\n",
    "logged_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For offline RL and OPE procedures, please refer to [examples/quickstart/basic/basic_synthetic_continuous_basic.ipynb](https://github.com/hakuhodo-technologies/scope-rl/blob/main/examples/quickstart/basic/basic_synthetic_continuous_basic.ipynb). \n",
    "\n",
    "For advanced topics regarding OPE and OPS, please refer to [examples/quickstart/basic/basic_synthetic_continuous_advanced.ipynb](https://github.com/hakuhodo-technologies/scope-rl/blob/main/examples/quickstart/basic/basic_synthetic_continuous_advanced.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- Yuta Saito, Shunsuke Aihara, Megumi Matsutani, and Yusuke Narita. \\\n",
    "\"Open Bandit Dataset and Pipeline: Towards Realistic and Reproducible Off-Policy Evaluation.\", 2021.\n",
    "\n",
    "- Takuma Seno and Michita Imai. \\\n",
    "\"d3rlpy: An Offline Deep Reinforcement Library.\", 2021.\n",
    "\n",
    "- Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine. \\\n",
    "\"Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor.\" 2018.\n",
    "\n",
    "- Di Wu, Xiujun Chen, Xun Yang, Hao Wang, Qing Tan, Xiaoxun Zhang, Jian Xu, and Kun Gai. \\\n",
    "\"Budget Constrained Bidding by Model-free Reinforcement Learning in Display Advertising.\", 2018.\n",
    "\n",
    "- Jun Zhao, Guang Qiu, Ziyu Guan, Wei Zhao, and Xiaofei He. \\\n",
    "\"Deep Reinforcement Learning for Sponsored Search Real-time Bidding.\", 2018.\n",
    "\n",
    "- Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. \\\n",
    "\"OpenAI Gym.\", 2016.\n",
    "\n",
    "- Hado van Hasselt, Arthur Guez, and David Silver. \\\n",
    "\"Deep Reinforcement Learning with Double Q-learning.\", 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "70404ee114725fce8ed9e697d67827f8546c678889944e6d695790702cbfe1f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
