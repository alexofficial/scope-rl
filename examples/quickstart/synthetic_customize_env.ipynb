{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart Example with Synthetic Simulation (Customization)\n",
    "This notebook provides an example of customizing the Recommender environment.\n",
    "\n",
    "This example on the Synthetic Recommender Simulation consists of the following 3 steps:\n",
    "1. Setup Synthetic Recommender Simulation Environment and Interacting Online RL Agent\n",
    "2. Standardized Environment\n",
    "3. Customize Environmental Configuration\n",
    "\n",
    "\\* This library uses [d3rlpy](https://github.com/takuseno/d3rlpy)'s algorithm implementations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# delete later\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete later\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete later\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OFRL modules\n",
    "import ofrl\n",
    "from ofrl.policy import OnlineHead\n",
    "from ofrl.policy import DiscreteEpsilonGreedyHead\n",
    "\n",
    "# import synthetic modules\n",
    "# import synthetic\n",
    "from syntheticgym import SyntheticEnv\n",
    "from syntheticgym import RewardFunction\n",
    "from syntheticgym import StateTransition\n",
    "from syntheticgym import BaseRewardFunction\n",
    "from syntheticgym import BaseStateTransition\n",
    "\n",
    "# import d3rlpy algorithms\n",
    "from d3rlpy.algos import DiscreteRandomPolicy\n",
    "from d3rlpy.algos import RandomPolicy as ContinuousRandomPolicy\n",
    "from d3rlpy.preprocessing import MinMaxActionScaler\n",
    "\n",
    "# import from other libraries\n",
    "import gym\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils import check_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Union, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0\n"
     ]
    }
   ],
   "source": [
    "# version\n",
    "print(ofrl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random state\n",
    "random_state = 12345\n",
    "random_ = check_random_state(random_state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Synthetic Recommender Simulation Environment and Interacting Online RL Agent\n",
    "To begin with, we briefly describe the basic usage of the environment.\n",
    "\n",
    "#### RL setup for Recommendation\n",
    "In recommendation, the objective of the RL agent is to maximize reward\n",
    "\n",
    "We often formulate this recommendation problem as the following (Partially Observable) Markov Decision Process ((PO)MDP):\n",
    "- `state`: \n",
    "   - A vector representing user preference.  The preference changes over time in an episode by the actions presented by the RL agent.\n",
    "   - When the true state is unobservable, you can gain observation instead of state.\n",
    "- `action`:  Index of an item to present to the user.\n",
    "- `reward`: User engagement signal. Either binary or continuous.\n",
    "\n",
    "Let's see how it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup environment\n",
    "env = SyntheticEnv(action_type='continuous', random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a random agent\n",
    "agent = OnlineHead(\n",
    "    ContinuousRandomPolicy(\n",
    "        action_scaler=MinMaxActionScaler(\n",
    "            minimum=0.1,  # minimum value that policy can take\n",
    "            maximum=10,  # maximum value that policy can take\n",
    "        )\n",
    "    ),\n",
    "    name=\"random\",\n",
    ")\n",
    "agent.build_with_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OnlineHead(base_policy=d3rlpy.algos.random_policy.RandomPolicy(action_scaler=d3rlpy.preprocessing.action_scalers.MinMaxActionScaler(minimum=0.1, maximum=10), action_size=3, batch_size=1, distribution='uniform', gamma=0.0, generated_maxlen=100000, impl=None, n_frames=1, n_steps=1, normal_std=1.0, real_ratio=1.0, reward_scaler=None, scaler=None), name='random')\n",
      "Box(-0.1, 10.0, (3,), float64)\n",
      "Box(-inf, inf, (5,), float64)\n"
     ]
    }
   ],
   "source": [
    "print(agent)\n",
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e5b94bf6ce41a99ae8645cb67a0ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[calculate on-policy policy value]:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ofrl\n",
    "from ofrl.ope.online import calc_on_policy_policy_value\n",
    "# calculate on-policy policy value\n",
    "on_policy_performance = calc_on_policy_policy_value(\n",
    "  env,\n",
    "  agent,\n",
    "  n_trajectories=100,\n",
    "  random_state=12345\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.424295105862814\n"
     ]
    }
   ],
   "source": [
    "print(on_policy_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interact agent with the environment\n",
    "# only 6 lines are needed for RL interaction\n",
    "for episode in range(10):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = agent.sample_action_online(obs)\n",
    "        obs, reward, done, truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "[ 0.00987027 -0.44329176 -0.36035872 -0.77317723  0.27519731]\n"
     ]
    }
   ],
   "source": [
    "# state \n",
    "print(obs.shape)\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's visualize the transition of reward\n",
    "def visualize_interaction_on_environment(env, agent):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    reward_list = []\n",
    "\n",
    "    while not done:\n",
    "        action = agent.sample_action_online(obs)\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        reward_list.append(reward)\n",
    "\n",
    "    # plot\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.plot(reward_list[:-1], label='reward', color='tab:orange')\n",
    "    ax1.set_xlabel('timestep')\n",
    "    ax1.set_ylabel('reward')\n",
    "    ax1.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "visualize_interaction_on_environment(env, agent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Standardized Environment\n",
    "\n",
    "We provide standardize recommender environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SyntheticEnv(random_state=12345)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Customize Environmental Configuration\n",
    "Now, we customize the recommender simulation environment.\n",
    "\n",
    "We have the following environmental configurations:\n",
    "- `StateTransition`: State transition of the synthetic simulation.\n",
    "- `RewardFunction`: Reward function of the synthetic simulation.\n",
    "- `state_dim`: Dimensions of state.\n",
    "- `action_type`: action type (i.e., continuous / discrete).\n",
    "- `n_actions`: Number of actions. Applicable only when reward_type is \"discrete\".\n",
    "- `action_context_dim`: Dimensions of the action context.\n",
    "- `action_context`: Feature vectors that characterizes each action.\n",
    "- `reward_type`: Reward type (i.e., continuous / binary).\n",
    "- `reward_std`: Standard deviation of the reward distribution. Applicable only when reward_type is \"continuous\".\n",
    "- `obs_std`: Standard deviation of the observation distribution.\n",
    "- `step_per_episode`: Number of timesteps in an episode.\n",
    "- `random_state` : Random state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 1. Customizing the Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [119], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m env \u001b[39m=\u001b[39m SyntheticEnv(\n\u001b[1;32m      2\u001b[0m         StateTransition \u001b[39m=\u001b[39m StateTransition,\n\u001b[1;32m      3\u001b[0m         RewardFunction \u001b[39m=\u001b[39m RewardFunction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m         random_state \u001b[39m=\u001b[39m \u001b[39m12345\u001b[39m,\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m visualize_interaction_on_environment(env, agent)\n",
      "Cell \u001b[0;32mIn [117], line 9\u001b[0m, in \u001b[0;36mvisualize_interaction_on_environment\u001b[0;34m(env, agent)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[1;32m      8\u001b[0m     action \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39msample_action_online(obs)\n\u001b[0;32m----> 9\u001b[0m     obs, reward, done, truncated, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     10\u001b[0m     reward_list\u001b[39m.\u001b[39mappend(reward)\n\u001b[1;32m     12\u001b[0m \u001b[39m# plot\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/ofrl/examples/quickstart/../../syntheticgym/envs/synthetic.py:184\u001b[0m, in \u001b[0;36mSyntheticEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39m\"\"\"Simulate a recommender interaction with a user.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[39mNote\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m \n\u001b[1;32m    182\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m# 1. sample reward for the given item.\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m reward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreward_function\u001b[39m.\u001b[39;49msample(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate, action)\n\u001b[1;32m    186\u001b[0m \u001b[39m# 2. update user state with state_transition\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_transition\u001b[39m.\u001b[39mstep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, action)\n",
      "File \u001b[0;32m~/dev/ofrl/examples/quickstart/../../syntheticgym/envs/simulator/function.py:169\u001b[0m, in \u001b[0;36mRewardFunction.sample\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39m\"\"\"Reward function. inner product of state and recommended item_feature\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \n\u001b[1;32m    153\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcontinuous\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 169\u001b[0m     reward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_coef\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m state \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_dim \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_coef\u001b[39m.\u001b[39;49mT \u001b[39m@\u001b[39;49m action \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_context_dim \u001b[39m+\u001b[39m state\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_action_coef \u001b[39m@\u001b[39m action) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_dim \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_context_dim\n\u001b[1;32m    171\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdiscrete\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    172\u001b[0m     reward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_coef\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m state \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_dim \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_coef\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_context[action] \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_context_dim \u001b[39m+\u001b[39m state\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_action_coef \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_context[action]) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_dim \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_context_dim\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 10)"
     ]
    }
   ],
   "source": [
    "env = SyntheticEnv(\n",
    "        StateTransition = StateTransition,\n",
    "        RewardFunction = RewardFunction,\n",
    "        state_dim = 5,\n",
    "        action_type = \"continuous\",  # \"discrete\"\n",
    "        action_context_dim = 10,\n",
    "        action_context = None,\n",
    "        reward_type = \"continuous\",  # \"binary\"\n",
    "        reward_std = 0.0,\n",
    "        obs_std = 0.0,\n",
    "        step_per_episode = 10,\n",
    "        random_state = 12345,\n",
    ")\n",
    "visualize_interaction_on_environment(env, agent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 2. Defining the action_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (729911845.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [18], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    action_context =\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# we use the following items for recommendation\n",
    "action_context = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user3</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user5</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user96</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user97</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user98</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user99</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user100</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature1  feature2  feature3  feature4  feature5\n",
       "user1          -1        -1        -1         1         1\n",
       "user2          -1        -1         1         1        -1\n",
       "user3          -1        -1         1         1        -1\n",
       "user4           1         1         1         1         1\n",
       "user5          -1        -1         1         1         1\n",
       "...           ...       ...       ...       ...       ...\n",
       "user96         -1        -1        -1        -1         1\n",
       "user97          1        -1         1         1        -1\n",
       "user98          1        -1         1        -1        -1\n",
       "user99         -1         1        -1         1        -1\n",
       "user100         1        -1        -1         1         1\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we assume that the following 100 users \n",
    "user_features = np.sign(random_.normal(size=(100, 5))).astype(int)\n",
    "user_names, feature_names = [f\"user{i+1}\" for i in range(100)], [f\"feature{i+1}\" for i in range(5)]\n",
    "user_df = pd.DataFrame(user_features, columns=feature_names, index=user_names)\n",
    "user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'UserModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# using the above data, we can simulate an recommendation as follows\u001b[39;00m\n\u001b[1;32m      2\u001b[0m env \u001b[39m=\u001b[39m SyntheticEnv(\n\u001b[0;32m----> 3\u001b[0m         UserModel \u001b[39m=\u001b[39m UserModel,\n\u001b[1;32m      4\u001b[0m         n_items \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m,  \u001b[39m# we use 100 items\u001b[39;00m\n\u001b[1;32m      5\u001b[0m         n_users \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m,  \u001b[39m# 100 users exists\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         item_feature_dim \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,  \u001b[39m#each item has 5 dimensional features\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         user_feature_dim \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,  \u001b[39m#each user has 5 dimensional features\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         item_feature_vector \u001b[39m=\u001b[39m item_features, \u001b[39m# use item features defined above\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         user_feature_vector \u001b[39m=\u001b[39m user_features, \u001b[39m# use user features defined above\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         reward_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcontinuous\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m#we use continuous reward\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         reward_std \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m,\n\u001b[1;32m     12\u001b[0m         obs_std \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m, \u001b[39m#not add noise to the observation\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         step_per_episode \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m,\n\u001b[1;32m     14\u001b[0m         random_state \u001b[39m=\u001b[39m \u001b[39m12345\u001b[39m,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m visualize_interaction_on_environment(env, agent)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'UserModel' is not defined"
     ]
    }
   ],
   "source": [
    "# using the above data, we can simulate an recommendation as follows\n",
    "env = SyntheticEnv(\n",
    "        UserModel = UserModel,\n",
    "        n_items = 100,  # we use 100 items\n",
    "        n_users = 100,  # 100 users exists\n",
    "        item_feature_dim = 5,  #each item has 5 dimensional features\n",
    "        user_feature_dim = 5,  #each user has 5 dimensional features\n",
    "        item_feature_vector = item_features, # use item features defined above\n",
    "        user_feature_vector = user_features, # use user features defined above\n",
    "        reward_type = \"continuous\", #we use continuous reward\n",
    "        reward_std = 0.0,\n",
    "        obs_std = 0.0, #not add noise to the observation\n",
    "        step_per_episode = 10,\n",
    "        random_state = 12345,\n",
    ")\n",
    "visualize_interaction_on_environment(env, agent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 3. Using Customized UserModel(reward_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthetic import BaseUserModel\n",
    "from synthetic import Action\n",
    "\n",
    "@dataclass\n",
    "class UserModel(BaseUserModel):\n",
    "    reward_type: str = \"continuous\"  # \"binary\"\n",
    "    reward_std: float = 0.0\n",
    "    item_feature_vector: Optional[np.ndarray] = None,\n",
    "    random_state: Optional[int] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        check_scalar(\n",
    "            self.reward_std,\n",
    "            name=\"reward_std\",\n",
    "            target_type=float,\n",
    "        )\n",
    "\n",
    "        if self.reward_type not in [\"continuous\", \"binary\"]:\n",
    "            raise ValueError(\n",
    "                f'reward_type must be either \"continuous\" or \"binary\", but {self.reward_type} is given'\n",
    "            )\n",
    "\n",
    "        self.random_ = check_random_state(self.random_state)\n",
    "\n",
    "    def user_preference_dynamics(\n",
    "        self,\n",
    "        state: np.ndarray,\n",
    "        action: Action,\n",
    "        alpha: float = 1.0,\n",
    "    )-> np.ndarray:\n",
    "        \n",
    "        check_scalar(\n",
    "            state,\n",
    "            name=\"state\",\n",
    "            target_type=np.ndarray,\n",
    "        )\n",
    "        check_scalar(\n",
    "            action,\n",
    "            name=\"action\",\n",
    "            target_type=Action,\n",
    "        )\n",
    "\n",
    "        state = (state + alpha * state @ self.item_feature_vector[action] * self.item_feature_vector[action])\n",
    "        state = state / np.linalg.norm(state, ord=2)\n",
    "        return state\n",
    "\n",
    "    def reward_function(\n",
    "        self,\n",
    "        state: np.ndarray,\n",
    "        action: Action,\n",
    "    )-> float:\n",
    "        reward = self.cos_similar_function(state, action)\n",
    "\n",
    "        if self.reward_type is \"continuous\":\n",
    "            reward = reward + self.random_.normal(loc=0.0, scale=self.reward_std)\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def cos_similar_function(\n",
    "        self,\n",
    "        state: np.ndarray,\n",
    "        action: Action,\n",
    "    )-> float:\n",
    "        inner = state @ self.item_feature_vector[action]\n",
    "        reward = inner / (np.linalg.norm(state, ord=2) * np.linalg.norm(self.item_feature_vector[action], ord=2))\n",
    "\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup environment\n",
    "env = SyntheticEnv(\n",
    "    UserModel = UserModel,\n",
    "    reward_type = \"continuous\",\n",
    "    random_state=12345\n",
    ")\n",
    "visualize_interaction_on_environment(env, agent)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 4. Using Customized UserModel(user_preference_dynamics and reward_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthetic import BaseUserModel\n",
    "from synthetic import Action\n",
    "\n",
    "@dataclass\n",
    "class UserModel(BaseUserModel):\n",
    "    reward_type: str = \"continuous\"  # \"binary\"\n",
    "    reward_std: float = 0.0\n",
    "    item_feature_vector: Optional[np.ndarray] = None,\n",
    "    random_state: Optional[int] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        check_scalar(\n",
    "            self.reward_std,\n",
    "            name=\"reward_std\",\n",
    "            target_type=float,\n",
    "        )\n",
    "\n",
    "        if self.reward_type not in [\"continuous\", \"binary\"]:\n",
    "            raise ValueError(\n",
    "                f'reward_type must be either \"continuous\" or \"binary\", but {self.reward_type} is given'\n",
    "            )\n",
    "\n",
    "        self.random_ = check_random_state(self.random_state)\n",
    "\n",
    "    def user_preference_dynamics(\n",
    "        self,\n",
    "        state: np.ndarray,\n",
    "        action: Action,\n",
    "        alpha: float = 1.0,\n",
    "    )-> np.ndarray:\n",
    "        \n",
    "        check_scalar(\n",
    "            state,\n",
    "            name=\"state\",\n",
    "            target_type=np.ndarray,\n",
    "        )\n",
    "        check_scalar(\n",
    "            action,\n",
    "            name=\"action\",\n",
    "            target_type=Action,\n",
    "        )\n",
    "\n",
    "        if self.reward == 1:\n",
    "            state = (state + alpha * state @ self.item_feature_vector[action] * self.item_feature_vector[action])\n",
    "            state = state / np.linalg.norm(state, ord=2)\n",
    "            \n",
    "        return state\n",
    "\n",
    "    def reward_function(\n",
    "        self,\n",
    "        state: np.ndarray,\n",
    "        action: Action,\n",
    "    )-> float:\n",
    "        self.reward = self.random_.binomial(n=1, p=self.sigmoid(self.cos_similar_function(state, action)))\n",
    "\n",
    "        if self.reward_type is \"continuous\":\n",
    "            reward = reward + self.random_.normal(loc=0.0, scale=self.reward_std)\n",
    "\n",
    "        return self.reward\n",
    "\n",
    "    def cos_similar_function(\n",
    "        self,\n",
    "        state: np.ndarray,\n",
    "        action: Action,\n",
    "    )-> float:\n",
    "        inner = state @ self.item_feature_vector[action]\n",
    "        reward = inner / (np.linalg.norm(state, ord=2) * np.linalg.norm(self.item_feature_vector[action], ord=2))\n",
    "\n",
    "        return reward\n",
    "    \n",
    "    def sigmoid(self, x: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n",
    "    # Sigmoid function\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup environment\n",
    "env = SyntheticEnv(\n",
    "    UserModel = UserModel,\n",
    "    reward_type = \"binary\",\n",
    "    random_state=12345\n",
    ")\n",
    "visualize_interaction_on_environment(env, agent)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Customize Bidding Setup in RTB Env\n",
    "Here, we describe how the decision makers can customize their own RTB environment.  \n",
    "Specifically, they can setup their own action space and bid price calculation rules by defining the following modules.\n",
    "- `reward_predictor` in Bidder class  \n",
    "    We use predicted rewards to calculate the bid price.  \n",
    "        bid price = adjust rate * predicted reward ( * constant)\n",
    "    If None, we use the ground-truth reward instead of the predicted reward.  \n",
    "\n",
    "- `scaler` in Bidder class\n",
    "    Scaler defines constant in the bid price calculation.  \n",
    "        bid price = adjust rate * predicted reward ( * constant)\n",
    "        constant = scaler * standard_bid_price\n",
    "    where standard_bid_price indicates the average of standard_bid_price  \n",
    "    (bid price which has approximately 50% impression probability) over all ads.\n",
    "\n",
    "- `action_space` for agent  \n",
    "    We transform continual adjust rate space $[0, \\infty)$ into agent action space $[0.1, 10]$.  \n",
    "    Both discrete and continuous actions are acceptable.  \n",
    "    (We can tune multiplication of adjust rate using scaler.)\n",
    "    \n",
    "The arguments are given as follows:\n",
    "- `original_env`: Original RTB Environment.\n",
    "- `reward_predictor`: A machine learning model to predict the reward to determine the bidding price.\n",
    "- `scaler`: Scaling factor (constant value) used for bid price determination. (`None` for the auto-fitting)\n",
    "- `action_min`: Minimum value of adjust rate.\n",
    "- `action_max`: Maximum value of adjust rate.\n",
    "- `action_type`: Action type of the RL agent, which should either be \"discrete\" or \"continuous\".\n",
    "- `n_actions`: Number of \"discrete\" actions.\n",
    "- `action_meaning`: Mapping function of agent action index to the actual \"discrete\" action to take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize environment\n",
    "env = SyntheticEnv(random_state=random_state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 1. Defining Continuous Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's customize the continuous action space\n",
    "env = SyntheticEnv(\n",
    "    original_env=env,\n",
    "    action_type=\"continuous\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a random agent\n",
    "agent = DiscreteEpsilonGreedyHead(\n",
    "      base_policy = DiscreteRandomPolicy(),\n",
    "      name = 'random',\n",
    "      n_actions = env.n_actions,\n",
    "      epsilon = 1. ,\n",
    "      random_state = random_state, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(custom_env.action_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another example\n",
    "custom_env = SyntheticEnv(\n",
    "    original_env=env,\n",
    "    action_min=0.1,\n",
    "    action_max=0.5,\n",
    "    action_type=\"continuous\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(custom_env.action_space)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 2. Defining Discrete Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's customize the environment and discretize the action space\n",
    "custom_env = SyntheticEnv(\n",
    "    random_state=random_state,\n",
    "    action_type=\"discrete\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(100)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SyntheticEnv' object has no attribute 'action_meaning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [168], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(custom_env\u001b[39m.\u001b[39maction_space)\n\u001b[0;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(custom_env\u001b[39m.\u001b[39;49maction_meaning)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SyntheticEnv' object has no attribute 'action_meaning'"
     ]
    }
   ],
   "source": [
    "print(custom_env.action_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another example\n",
    "custom_env = SyntheticEnv(\n",
    "    original_env=env,\n",
    "    action_type=\"discrete\",\n",
    "    n_actions=5,\n",
    "    action_meaning=np.arange(1, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(custom_env.action_space)\n",
    "print(custom_env.action_meaning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- Sarah Dean, Jamie Morgenstern. \\\n",
    "\"Preference Dynamics Under Personalized Recommendations.\", 2022.\n",
    "\n",
    "- Takuma Seno and Michita Imai. \\\n",
    "\"d3rlpy: An Offline Deep Reinforcement Library.\", 2021.\n",
    "\n",
    "- David Rohde, Stephen Bonner, Travis Dunlop, Flavian Vasile, Alexandros Karatzoglou. \\\n",
    "\"RecoGym: A Reinforcement Learning Environment for the Problem of Product Recommendation in Online Advertising.\" 2018.\n",
    "\n",
    "- Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. \\\n",
    "\"OpenAI Gym.\", 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('3.10.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Sep 10 2022, 14:58:52) [Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "70404ee114725fce8ed9e697d67827f8546c678889944e6d695790702cbfe1f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
