{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart Example with Synthetic Recommendation Simulation and Dataset (Data Collection)\n",
    "This notebook provides an example of visualizing the logged dataset collected on an recommendation environment.\n",
    "\n",
    "This example on consists of the following case:\n",
    "1. Discrete Action Case\n",
    "\n",
    "\\* This library uses [d3rlpy](https://github.com/takuseno/d3rlpy)'s algorithm implementations.  \n",
    "\\* Also, our data collection module is highly inspired by [Open Bandit Pipeline](https://github.com/st-tech/zr-obp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# delete later\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "import d3rlpy\n",
    "print(d3rlpy.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete later\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete later\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OFRL modules\n",
    "import ofrl\n",
    "from ofrl.dataset import SyntheticDataset\n",
    "from ofrl.policy import OnlineHead\n",
    "from ofrl.policy import DiscreteEpsilonGreedyHead\n",
    "from ofrl.ope.online import (\n",
    "    calc_on_policy_policy_value,\n",
    "    visualize_on_policy_policy_value,\n",
    ")\n",
    "\n",
    "# import recgym\n",
    "from recgym import RECEnv\n",
    "from recgym import inner_reward_function\n",
    "from recgym import user_preference_dynamics\n",
    "\n",
    "# import d3rlpy algorithms\n",
    "from d3rlpy.algos import DiscreteRandomPolicy\n",
    "\n",
    "# import from other libraries\n",
    "import gym\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Union, Optional\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0\n"
     ]
    }
   ],
   "source": [
    "# version\n",
    "print(ofrl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random state\n",
    "random_state = 12345\n",
    "random_ = check_random_state(random_state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Description of Synthetic Recommendation Simulation Environment\n",
    "\n",
    "To begin with, we briefly describe the basic usage of the environment.\n",
    "\n",
    "#### RL setup for Recommendation\n",
    "In recommendation, the objective of the RL agent is to maximize reward\n",
    "\n",
    "We often formulate this recommendation problem as the following Markov Decision Process (MDP):\n",
    "- `state`: \n",
    "   - make the initial state the user_feature of the chosen user\n",
    "   - update state with state_transition_function\n",
    "- `action`: selected from n_items\n",
    "- `reward`: rewards are determined by reward_function\n",
    "\n",
    "Let's see how it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup environment\n",
    "env = RECEnv(\n",
    "    reward_function = inner_reward_function,\n",
    "    state_transition_function = user_preference_dynamics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DiscreteEpsilonGreedyHead(\n",
    "      base_policy = DiscreteRandomPolicy(),\n",
    "      name = 'random',\n",
    "      n_actions = env.n_items,\n",
    "      epsilon = 1. ,\n",
    "      random_state = random_state, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interact agent with the environment\n",
    "# only 6 lines are needed for RL interaction\n",
    "for episode in range(10):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = agent.sample_action_online(obs)\n",
    "        obs, reward, done, truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "[ 0.08530921  0.44150621 -0.53606009  0.47066649  0.28324795]\n"
     ]
    }
   ],
   "source": [
    "# state \n",
    "print(obs.shape)\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's visualize the transition of reward\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "reward_list = []\n",
    "\n",
    "while not done:\n",
    "    action = agent.sample_action_online(obs)\n",
    "\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    reward_list.append(reward)\n",
    "\n",
    "# plot\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(reward_list[:-1], label='reward', color='tab:orange')\n",
    "ax1.set_xlabel('timestep')\n",
    "ax1.set_ylabel('reward')\n",
    "ax1.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more about the environmental configuration , please refer to [examples/quickstart/REC_synthetic_customize_env.ipynb](https://github.com/negocia-inc/REC_reinforcement_learing/blob/ope/examples/quickstart/REC_synthetic_customize_env.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Discrete Action Case\n",
    "Here, we present how to collect logged data by a behavior policy in the case of discrete action.\n",
    "\n",
    "The procedure requires two steps:\n",
    "\n",
    "1. Learn a base deterministic policy\n",
    "2. Convert the deterministic policy into a stochastic policy.\n",
    "\n",
    "Below, we first learn a deterministic policy using [d3rlpy](https://github.com/takuseno/d3rlpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized environment for discrete action\n",
    "env = RECEnv(\n",
    "    reward_function = inner_reward_function, \n",
    "    state_transition_function = user_preference_dynamics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for api compatibility to d3rlpy\n",
    "from ofrl.utils import OldGymAPIWrapper\n",
    "env_ = OldGymAPIWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn a base deterministic policy for data collection\n",
    "from d3rlpy.algos import DoubleDQN\n",
    "from d3rlpy.models.encoders import VectorEncoderFactory\n",
    "from d3rlpy.models.q_functions import MeanQFunctionFactory\n",
    "from d3rlpy.online.buffers import ReplayBuffer\n",
    "from d3rlpy.online.explorers import LinearDecayEpsilonGreedy\n",
    "\n",
    "# model\n",
    "ddqn = DoubleDQN(\n",
    "    encoder_factory=VectorEncoderFactory(hidden_units=[30, 30]),\n",
    "    q_func_factory=MeanQFunctionFactory(),\n",
    "    target_update_interval=100,\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    ")\n",
    "# replay buffer\n",
    "buffer = ReplayBuffer(\n",
    "    maxlen=10000,\n",
    "    env=env_,\n",
    ")\n",
    "# explorers\n",
    "explorer = LinearDecayEpsilonGreedy(\n",
    "    start_epsilon=1.0,\n",
    "    end_epsilon=0.1,\n",
    "    duration=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-10 13:35.44 [info     ] Directory is created at d3rlpy_logs/DoubleDQN_online_20230110133544\n",
      "2023-01-10 13:35.44 [debug    ] Building model...\n",
      "2023-01-10 13:35.44 [debug    ] Model has been built.\n",
      "2023-01-10 13:35.44 [info     ] Parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/params.json params={'action_scaler': None, 'batch_size': 32, 'encoder_factory': {'type': 'vector', 'params': {'hidden_units': [30, 30], 'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None, 'use_dense': False}}, 'gamma': 0.99, 'generated_maxlen': 100000, 'learning_rate': 6.25e-05, 'n_critics': 1, 'n_frames': 1, 'n_steps': 1, 'optim_factory': {'optim_cls': 'Adam', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'real_ratio': 1.0, 'reward_scaler': None, 'scaler': None, 'target_update_interval': 100, 'use_gpu': None, 'algorithm': 'DoubleDQN', 'observation_shape': (5,), 'action_size': 99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93effc08a6841f4ba84efbebbbc5284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-10 13:35.44 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_1000.pt\n",
      "2023-01-10 13:35.44 [info     ] DoubleDQN_online_20230110133544: epoch=1 step=1000 epoch=1 metrics={'time_inference': 0.00011170077323913574, 'time_environment_step': 1.6529560089111328e-05, 'time_step': 0.0001357579231262207, 'rollout_return': -1.1892537577852698, 'evaluation': -3.4958189550380574} step=1000\n",
      "2023-01-10 13:35.45 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_2000.pt\n",
      "2023-01-10 13:35.45 [info     ] DoubleDQN_online_20230110133544: epoch=2 step=2000 epoch=2 metrics={'time_inference': 0.00012589311599731445, 'time_environment_step': 2.2648096084594725e-05, 'time_sample_batch': 2.733492851257324e-05, 'time_algorithm_update': 0.0006414864063262939, 'loss': 0.36437337973713874, 'time_step': 0.0008327703475952148, 'rollout_return': 5.331201435272556, 'evaluation': -0.28960941324173584} step=2000\n",
      "2023-01-10 13:35.46 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_3000.pt\n",
      "2023-01-10 13:35.46 [info     ] DoubleDQN_online_20230110133544: epoch=3 step=3000 epoch=3 metrics={'time_inference': 0.00012515044212341308, 'time_environment_step': 2.2689104080200197e-05, 'time_sample_batch': 2.8396844863891603e-05, 'time_algorithm_update': 0.0006100232601165772, 'loss': 0.7088170458376407, 'time_step': 0.0008015265464782715, 'rollout_return': 4.362457191122924, 'evaluation': 7.461636000821097} step=3000\n",
      "2023-01-10 13:35.47 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_4000.pt\n",
      "2023-01-10 13:35.47 [info     ] DoubleDQN_online_20230110133544: epoch=4 step=4000 epoch=4 metrics={'time_inference': 0.00012201428413391113, 'time_environment_step': 2.1958112716674806e-05, 'time_sample_batch': 2.7668952941894533e-05, 'time_algorithm_update': 0.0005910952091217041, 'loss': 1.6173852386176586, 'time_step': 0.0007775700092315673, 'rollout_return': 6.083881182207919, 'evaluation': 6.108108574835813} step=4000\n",
      "2023-01-10 13:35.47 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_5000.pt\n",
      "2023-01-10 13:35.47 [info     ] DoubleDQN_online_20230110133544: epoch=5 step=5000 epoch=5 metrics={'time_inference': 0.0001220245361328125, 'time_environment_step': 2.191162109375e-05, 'time_sample_batch': 2.805757522583008e-05, 'time_algorithm_update': 0.0005917971134185791, 'loss': 2.9143397503495216, 'time_step': 0.0007785911560058594, 'rollout_return': 7.4103992547885245, 'evaluation': 7.4056383050122365} step=5000\n",
      "2023-01-10 13:35.48 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_6000.pt\n",
      "2023-01-10 13:35.48 [info     ] DoubleDQN_online_20230110133544: epoch=6 step=6000 epoch=6 metrics={'time_inference': 0.00012194085121154785, 'time_environment_step': 2.1848440170288085e-05, 'time_sample_batch': 2.882719039916992e-05, 'time_algorithm_update': 0.0005853376388549804, 'loss': 4.396144353687763, 'time_step': 0.0007725272178649902, 'rollout_return': 7.5904787700436165, 'evaluation': 10.857022507861254} step=6000\n",
      "2023-01-10 13:35.49 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_7000.pt\n",
      "2023-01-10 13:35.49 [info     ] DoubleDQN_online_20230110133544: epoch=7 step=7000 epoch=7 metrics={'time_inference': 0.00011681437492370605, 'time_environment_step': 2.060079574584961e-05, 'time_sample_batch': 2.6721954345703125e-05, 'time_algorithm_update': 0.0005666015148162841, 'loss': 5.956196305036545, 'time_step': 0.0007446975708007812, 'rollout_return': 7.530445975581392, 'evaluation': 9.205669374810963} step=7000\n",
      "2023-01-10 13:35.50 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_8000.pt\n",
      "2023-01-10 13:35.50 [info     ] DoubleDQN_online_20230110133544: epoch=8 step=8000 epoch=8 metrics={'time_inference': 0.00011791110038757324, 'time_environment_step': 2.110600471496582e-05, 'time_sample_batch': 2.756810188293457e-05, 'time_algorithm_update': 0.0005739288330078125, 'loss': 7.43122865486145, 'time_step': 0.0007548320293426513, 'rollout_return': 7.868451510657298, 'evaluation': 8.729029689989016} step=8000\n",
      "2023-01-10 13:35.51 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_9000.pt\n",
      "2023-01-10 13:35.51 [info     ] DoubleDQN_online_20230110133544: epoch=9 step=9000 epoch=9 metrics={'time_inference': 0.00012242746353149415, 'time_environment_step': 2.2241592407226562e-05, 'time_sample_batch': 3.025174140930176e-05, 'time_algorithm_update': 0.0005928080081939697, 'loss': 8.610894217252731, 'time_step': 0.0007826504707336426, 'rollout_return': 8.1343493501686, 'evaluation': 11.105109412297464} step=9000\n",
      "2023-01-10 13:35.51 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_10000.pt\n",
      "2023-01-10 13:35.51 [info     ] DoubleDQN_online_20230110133544: epoch=10 step=10000 epoch=10 metrics={'time_inference': 0.00011813092231750488, 'time_environment_step': 2.0914316177368165e-05, 'time_sample_batch': 2.8296470642089843e-05, 'time_algorithm_update': 0.0005692248344421387, 'loss': 9.611806518793106, 'time_step': 0.0007505736351013184, 'rollout_return': 7.950564344962961, 'evaluation': 10.288279909396957} step=10000\n",
      "2023-01-10 13:35.52 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_11000.pt\n",
      "2023-01-10 13:35.52 [info     ] DoubleDQN_online_20230110133544: epoch=11 step=11000 epoch=11 metrics={'time_inference': 0.0001170969009399414, 'time_environment_step': 2.0637273788452148e-05, 'time_sample_batch': 2.7465343475341795e-05, 'time_algorithm_update': 0.00056093430519104, 'loss': 10.061629121541976, 'time_step': 0.000740546464920044, 'rollout_return': 6.615208321436516, 'evaluation': 9.59356607996128} step=11000\n",
      "2023-01-10 13:35.53 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_12000.pt\n",
      "2023-01-10 13:35.53 [info     ] DoubleDQN_online_20230110133544: epoch=12 step=12000 epoch=12 metrics={'time_inference': 0.00012093043327331543, 'time_environment_step': 2.195882797241211e-05, 'time_sample_batch': 2.9653787612915038e-05, 'time_algorithm_update': 0.0005804860591888428, 'loss': 10.743119571208954, 'time_step': 0.000768394947052002, 'rollout_return': 7.540403993153607, 'evaluation': 8.043327263558998} step=12000\n",
      "2023-01-10 13:35.54 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_13000.pt\n",
      "2023-01-10 13:35.54 [info     ] DoubleDQN_online_20230110133544: epoch=13 step=13000 epoch=13 metrics={'time_inference': 0.00013322257995605468, 'time_environment_step': 2.4395227432250976e-05, 'time_sample_batch': 3.3959865570068357e-05, 'time_algorithm_update': 0.000643885612487793, 'loss': 11.309411326169968, 'time_step': 0.0008529713153839112, 'rollout_return': 7.832711206734977, 'evaluation': 7.821551452510461} step=13000\n",
      "2023-01-10 13:35.54 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_14000.pt\n",
      "2023-01-10 13:35.54 [info     ] DoubleDQN_online_20230110133544: epoch=14 step=14000 epoch=14 metrics={'time_inference': 0.0001179521083831787, 'time_environment_step': 2.1277427673339844e-05, 'time_sample_batch': 2.8689384460449217e-05, 'time_algorithm_update': 0.0005742421150207519, 'loss': 11.824545210123063, 'time_step': 0.0007572610378265381, 'rollout_return': 6.770065238893244, 'evaluation': 3.0621209372487908} step=14000\n",
      "2023-01-10 13:35.55 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_15000.pt\n",
      "2023-01-10 13:35.55 [info     ] DoubleDQN_online_20230110133544: epoch=15 step=15000 epoch=15 metrics={'time_inference': 0.00011591649055480958, 'time_environment_step': 2.0342588424682616e-05, 'time_sample_batch': 2.7460575103759765e-05, 'time_algorithm_update': 0.0005591645240783692, 'loss': 12.383650378465653, 'time_step': 0.0007376241683959961, 'rollout_return': 7.63171622852112, 'evaluation': 6.087432494020893} step=15000\n",
      "2023-01-10 13:35.56 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_16000.pt\n",
      "2023-01-10 13:35.56 [info     ] DoubleDQN_online_20230110133544: epoch=16 step=16000 epoch=16 metrics={'time_inference': 0.00012368583679199218, 'time_environment_step': 2.166867256164551e-05, 'time_sample_batch': 2.9221773147583007e-05, 'time_algorithm_update': 0.0006019079685211182, 'loss': 12.654543045759201, 'time_step': 0.0007919414043426514, 'rollout_return': 7.333511854205337, 'evaluation': 10.124768470642511} step=16000\n",
      "2023-01-10 13:35.57 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_17000.pt\n",
      "2023-01-10 13:35.57 [info     ] DoubleDQN_online_20230110133544: epoch=17 step=17000 epoch=17 metrics={'time_inference': 0.00012135434150695801, 'time_environment_step': 2.1835803985595703e-05, 'time_sample_batch': 3.0338287353515626e-05, 'time_algorithm_update': 0.0005796911716461181, 'loss': 12.968930259108543, 'time_step': 0.0007688231468200683, 'rollout_return': 6.83789652491927, 'evaluation': 5.225562030838032} step=17000\n",
      "2023-01-10 13:35.58 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_18000.pt\n",
      "2023-01-10 13:35.58 [info     ] DoubleDQN_online_20230110133544: epoch=18 step=18000 epoch=18 metrics={'time_inference': 0.00012562942504882812, 'time_environment_step': 2.2891759872436524e-05, 'time_sample_batch': 3.185415267944336e-05, 'time_algorithm_update': 0.000597564697265625, 'loss': 13.478667369127274, 'time_step': 0.0007942361831665039, 'rollout_return': 8.559650750659081, 'evaluation': 7.513156829820271} step=18000\n",
      "2023-01-10 13:35.58 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_19000.pt\n",
      "2023-01-10 13:35.58 [info     ] DoubleDQN_online_20230110133544: epoch=19 step=19000 epoch=19 metrics={'time_inference': 0.00012552642822265625, 'time_environment_step': 2.3309707641601563e-05, 'time_sample_batch': 3.1797409057617186e-05, 'time_algorithm_update': 0.0006036632061004639, 'loss': 13.697579126119614, 'time_step': 0.0008008475303649902, 'rollout_return': 7.392899679268574, 'evaluation': 5.68410481092323} step=19000\n",
      "2023-01-10 13:35.59 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_20000.pt\n",
      "2023-01-10 13:35.59 [info     ] DoubleDQN_online_20230110133544: epoch=20 step=20000 epoch=20 metrics={'time_inference': 0.00011831808090209961, 'time_environment_step': 2.100682258605957e-05, 'time_sample_batch': 2.8354644775390624e-05, 'time_algorithm_update': 0.0005682439804077148, 'loss': 13.95507219171524, 'time_step': 0.0007508606910705567, 'rollout_return': 7.069413939685558, 'evaluation': 9.232292012882867} step=20000\n",
      "2023-01-10 13:36.00 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_21000.pt\n",
      "2023-01-10 13:36.00 [info     ] DoubleDQN_online_20230110133544: epoch=21 step=21000 epoch=21 metrics={'time_inference': 0.00012134671211242675, 'time_environment_step': 2.2313833236694335e-05, 'time_sample_batch': 3.0681371688842776e-05, 'time_algorithm_update': 0.0005861268043518066, 'loss': 14.192167775630951, 'time_step': 0.0007763967514038086, 'rollout_return': 7.690269648953421, 'evaluation': 8.668529200376554} step=21000\n",
      "2023-01-10 13:36.01 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_22000.pt\n",
      "2023-01-10 13:36.01 [info     ] DoubleDQN_online_20230110133544: epoch=22 step=22000 epoch=22 metrics={'time_inference': 0.00013094353675842285, 'time_environment_step': 2.4132251739501954e-05, 'time_sample_batch': 3.2726764678955076e-05, 'time_algorithm_update': 0.0006419665813446045, 'loss': 14.05469077205658, 'time_step': 0.000846987009048462, 'rollout_return': 7.895805795417981, 'evaluation': 6.5892390773557565} step=22000\n",
      "2023-01-10 13:36.02 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_23000.pt\n",
      "2023-01-10 13:36.02 [info     ] DoubleDQN_online_20230110133544: epoch=23 step=23000 epoch=23 metrics={'time_inference': 0.00011943316459655762, 'time_environment_step': 2.1505117416381835e-05, 'time_sample_batch': 2.8716087341308594e-05, 'time_algorithm_update': 0.0005764284133911133, 'loss': 14.561179510593414, 'time_step': 0.0007612059116363525, 'rollout_return': 7.338673710715654, 'evaluation': 11.029129719337046} step=23000\n",
      "2023-01-10 13:36.02 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_24000.pt\n",
      "2023-01-10 13:36.02 [info     ] DoubleDQN_online_20230110133544: epoch=24 step=24000 epoch=24 metrics={'time_inference': 0.00011626839637756348, 'time_environment_step': 2.0796060562133788e-05, 'time_sample_batch': 2.747964859008789e-05, 'time_algorithm_update': 0.0005637242794036865, 'loss': 14.802834987163545, 'time_step': 0.000742943286895752, 'rollout_return': 7.821427902829237, 'evaluation': 9.55115814416121} step=24000\n",
      "2023-01-10 13:36.03 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_25000.pt\n",
      "2023-01-10 13:36.03 [info     ] DoubleDQN_online_20230110133544: epoch=25 step=25000 epoch=25 metrics={'time_inference': 0.00011637043952941895, 'time_environment_step': 2.0664453506469727e-05, 'time_sample_batch': 2.7574777603149413e-05, 'time_algorithm_update': 0.0005608603954315185, 'loss': 14.844803057670592, 'time_step': 0.0007400567531585694, 'rollout_return': 8.025536720463041, 'evaluation': 9.016972322902065} step=25000\n",
      "2023-01-10 13:36.04 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_26000.pt\n",
      "2023-01-10 13:36.04 [info     ] DoubleDQN_online_20230110133544: epoch=26 step=26000 epoch=26 metrics={'time_inference': 0.00011955428123474121, 'time_environment_step': 2.1389484405517578e-05, 'time_sample_batch': 2.9439449310302733e-05, 'time_algorithm_update': 0.0005707955360412598, 'loss': 15.154670431137085, 'time_step': 0.0007563564777374268, 'rollout_return': 7.4698168628081625, 'evaluation': 7.636919504704233} step=26000\n",
      "2023-01-10 13:36.05 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_27000.pt\n",
      "2023-01-10 13:36.05 [info     ] DoubleDQN_online_20230110133544: epoch=27 step=27000 epoch=27 metrics={'time_inference': 0.0001172480583190918, 'time_environment_step': 2.0794630050659178e-05, 'time_sample_batch': 2.831578254699707e-05, 'time_algorithm_update': 0.00056770920753479, 'loss': 15.202414425849915, 'time_step': 0.0007487330436706543, 'rollout_return': 7.507754465210706, 'evaluation': 9.0563787735808} step=27000\n",
      "2023-01-10 13:36.06 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_28000.pt\n",
      "2023-01-10 13:36.06 [info     ] DoubleDQN_online_20230110133544: epoch=28 step=28000 epoch=28 metrics={'time_inference': 0.00011536502838134765, 'time_environment_step': 2.031254768371582e-05, 'time_sample_batch': 2.6740074157714845e-05, 'time_algorithm_update': 0.0005562989711761474, 'loss': 15.35066707611084, 'time_step': 0.0007329788208007812, 'rollout_return': 7.756799114449771, 'evaluation': 11.341049773550209} step=28000\n",
      "2023-01-10 13:36.06 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_29000.pt\n",
      "2023-01-10 13:36.06 [info     ] DoubleDQN_online_20230110133544: epoch=29 step=29000 epoch=29 metrics={'time_inference': 0.00011568331718444825, 'time_environment_step': 2.0528554916381835e-05, 'time_sample_batch': 2.719545364379883e-05, 'time_algorithm_update': 0.000561138391494751, 'loss': 15.536834225416184, 'time_step': 0.0007389905452728271, 'rollout_return': 7.795404428578963, 'evaluation': 3.137367755265386} step=29000\n",
      "2023-01-10 13:36.07 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_30000.pt\n",
      "2023-01-10 13:36.07 [info     ] DoubleDQN_online_20230110133544: epoch=30 step=30000 epoch=30 metrics={'time_inference': 0.00011835479736328125, 'time_environment_step': 2.1379947662353517e-05, 'time_sample_batch': 2.8804540634155273e-05, 'time_algorithm_update': 0.0005707089900970459, 'loss': 15.46780584025383, 'time_step': 0.0007541813850402832, 'rollout_return': 8.395573780044453, 'evaluation': 3.8583709519733738} step=30000\n",
      "2023-01-10 13:36.08 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_31000.pt\n",
      "2023-01-10 13:36.08 [info     ] DoubleDQN_online_20230110133544: epoch=31 step=31000 epoch=31 metrics={'time_inference': 0.00011639380455017089, 'time_environment_step': 2.0590782165527345e-05, 'time_sample_batch': 2.8385400772094727e-05, 'time_algorithm_update': 0.0005586669445037842, 'loss': 15.802046772480011, 'time_step': 0.0007386443614959717, 'rollout_return': 8.44384474851882, 'evaluation': 7.233238541432972} step=31000\n",
      "2023-01-10 13:36.09 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_32000.pt\n",
      "2023-01-10 13:36.09 [info     ] DoubleDQN_online_20230110133544: epoch=32 step=32000 epoch=32 metrics={'time_inference': 0.00011145472526550294, 'time_environment_step': 1.9594192504882812e-05, 'time_sample_batch': 2.4839878082275392e-05, 'time_algorithm_update': 0.0005460176467895508, 'loss': 15.83359406530857, 'time_step': 0.0007156839370727539, 'rollout_return': 8.43846910176831, 'evaluation': 8.137795949969759} step=32000\n",
      "2023-01-10 13:36.09 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_33000.pt\n",
      "2023-01-10 13:36.09 [info     ] DoubleDQN_online_20230110133544: epoch=33 step=33000 epoch=33 metrics={'time_inference': 0.00011076140403747559, 'time_environment_step': 1.9598245620727537e-05, 'time_sample_batch': 2.4556875228881835e-05, 'time_algorithm_update': 0.0005452275276184082, 'loss': 16.133658804893493, 'time_step': 0.0007138633728027343, 'rollout_return': 8.918218716325912, 'evaluation': 7.024245861724987} step=33000\n",
      "2023-01-10 13:36.10 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_34000.pt\n",
      "2023-01-10 13:36.10 [info     ] DoubleDQN_online_20230110133544: epoch=34 step=34000 epoch=34 metrics={'time_inference': 0.00011456942558288574, 'time_environment_step': 2.028512954711914e-05, 'time_sample_batch': 2.6480674743652343e-05, 'time_algorithm_update': 0.0005553684234619141, 'loss': 16.29073703765869, 'time_step': 0.0007310898303985596, 'rollout_return': 8.477840249699263, 'evaluation': 8.681219641149465} step=34000\n",
      "2023-01-10 13:36.11 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_35000.pt\n",
      "2023-01-10 13:36.11 [info     ] DoubleDQN_online_20230110133544: epoch=35 step=35000 epoch=35 metrics={'time_inference': 0.00011704039573669434, 'time_environment_step': 2.0882129669189453e-05, 'time_sample_batch': 2.8115272521972658e-05, 'time_algorithm_update': 0.0005668337345123291, 'loss': 16.493971801280974, 'time_step': 0.0007477455139160156, 'rollout_return': 7.9179957806898855, 'evaluation': 6.482699424753728} step=35000\n",
      "2023-01-10 13:36.12 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_36000.pt\n",
      "2023-01-10 13:36.12 [info     ] DoubleDQN_online_20230110133544: epoch=36 step=36000 epoch=36 metrics={'time_inference': 0.00011699008941650391, 'time_environment_step': 2.0728826522827148e-05, 'time_sample_batch': 2.7994632720947267e-05, 'time_algorithm_update': 0.0005664720535278321, 'loss': 16.456022270560265, 'time_step': 0.0007469143867492676, 'rollout_return': 8.682898651163597, 'evaluation': 10.6449131103162} step=36000\n",
      "2023-01-10 13:36.12 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_37000.pt\n",
      "2023-01-10 13:36.12 [info     ] DoubleDQN_online_20230110133544: epoch=37 step=37000 epoch=37 metrics={'time_inference': 0.00012346601486206056, 'time_environment_step': 2.1716833114624024e-05, 'time_sample_batch': 2.8063058853149414e-05, 'time_algorithm_update': 0.0006049468517303467, 'loss': 16.810523407220842, 'time_step': 0.0007935540676116944, 'rollout_return': 7.882411650250235, 'evaluation': 4.583478583900584} step=37000\n",
      "2023-01-10 13:36.13 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_38000.pt\n",
      "2023-01-10 13:36.13 [info     ] DoubleDQN_online_20230110133544: epoch=38 step=38000 epoch=38 metrics={'time_inference': 0.00011713051795959473, 'time_environment_step': 2.091073989868164e-05, 'time_sample_batch': 2.7934789657592774e-05, 'time_algorithm_update': 0.0005673542022705078, 'loss': 16.866272864103315, 'time_step': 0.0007480919361114502, 'rollout_return': 8.818418698498313, 'evaluation': 11.429241965584309} step=38000\n",
      "2023-01-10 13:36.14 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_39000.pt\n",
      "2023-01-10 13:36.14 [info     ] DoubleDQN_online_20230110133544: epoch=39 step=39000 epoch=39 metrics={'time_inference': 0.00011178350448608398, 'time_environment_step': 1.9613742828369142e-05, 'time_sample_batch': 2.501845359802246e-05, 'time_algorithm_update': 0.0005470094680786133, 'loss': 16.681247557640077, 'time_step': 0.000717172384262085, 'rollout_return': 8.158245910826576, 'evaluation': 9.043788540696054} step=39000\n",
      "2023-01-10 13:36.15 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_40000.pt\n",
      "2023-01-10 13:36.15 [info     ] DoubleDQN_online_20230110133544: epoch=40 step=40000 epoch=40 metrics={'time_inference': 0.00011964058876037598, 'time_environment_step': 2.1355867385864256e-05, 'time_sample_batch': 2.892613410949707e-05, 'time_algorithm_update': 0.0005707862377166748, 'loss': 16.900640327453612, 'time_step': 0.000755774736404419, 'rollout_return': 8.186721715379223, 'evaluation': 10.58517693980857} step=40000\n",
      "2023-01-10 13:36.15 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_41000.pt\n",
      "2023-01-10 13:36.15 [info     ] DoubleDQN_online_20230110133544: epoch=41 step=41000 epoch=41 metrics={'time_inference': 0.00011666202545166015, 'time_environment_step': 2.081298828125e-05, 'time_sample_batch': 2.772235870361328e-05, 'time_algorithm_update': 0.0005638716220855713, 'loss': 16.911607136249543, 'time_step': 0.000743783950805664, 'rollout_return': 8.071541504168348, 'evaluation': 10.691968467039798} step=41000\n",
      "2023-01-10 13:36.16 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_42000.pt\n",
      "2023-01-10 13:36.16 [info     ] DoubleDQN_online_20230110133544: epoch=42 step=42000 epoch=42 metrics={'time_inference': 0.00011236667633056641, 'time_environment_step': 1.9684553146362305e-05, 'time_sample_batch': 2.5094032287597655e-05, 'time_algorithm_update': 0.0005490989685058594, 'loss': 17.460876299858093, 'time_step': 0.0007201957702636718, 'rollout_return': 8.026748748751356, 'evaluation': 6.6104499206209635} step=42000\n",
      "2023-01-10 13:36.17 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_43000.pt\n",
      "2023-01-10 13:36.17 [info     ] DoubleDQN_online_20230110133544: epoch=43 step=43000 epoch=43 metrics={'time_inference': 0.00012118053436279296, 'time_environment_step': 2.163863182067871e-05, 'time_sample_batch': 2.8804540634155273e-05, 'time_algorithm_update': 0.0005934057235717773, 'loss': 17.164215227127077, 'time_step': 0.0007804005146026612, 'rollout_return': 7.666851997159163, 'evaluation': 10.978037269904448} step=43000\n",
      "2023-01-10 13:36.18 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_44000.pt\n",
      "2023-01-10 13:36.18 [info     ] DoubleDQN_online_20230110133544: epoch=44 step=44000 epoch=44 metrics={'time_inference': 0.00012911748886108398, 'time_environment_step': 2.3180484771728515e-05, 'time_sample_batch': 3.22420597076416e-05, 'time_algorithm_update': 0.0006269750595092774, 'loss': 17.15775817477703, 'time_step': 0.0008283696174621582, 'rollout_return': 8.838887130136184, 'evaluation': 8.635415506362998} step=44000\n",
      "2023-01-10 13:36.19 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_45000.pt\n",
      "2023-01-10 13:36.19 [info     ] DoubleDQN_online_20230110133544: epoch=45 step=45000 epoch=45 metrics={'time_inference': 0.0001376986503601074, 'time_environment_step': 2.5278329849243165e-05, 'time_sample_batch': 3.4100294113159177e-05, 'time_algorithm_update': 0.000829726219177246, 'loss': 17.243795451641084, 'time_step': 0.0010477421283721924, 'rollout_return': 8.0918989839437, 'evaluation': 8.968389697203857} step=45000\n",
      "2023-01-10 13:36.20 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_46000.pt\n",
      "2023-01-10 13:36.20 [info     ] DoubleDQN_online_20230110133544: epoch=46 step=46000 epoch=46 metrics={'time_inference': 0.00015760087966918944, 'time_environment_step': 3.685760498046875e-05, 'time_sample_batch': 3.8083553314208986e-05, 'time_algorithm_update': 0.0007924354076385498, 'loss': 17.63916414999962, 'time_step': 0.001045961856842041, 'rollout_return': 9.037914977928487, 'evaluation': 9.686992270608473} step=46000\n",
      "2023-01-10 13:36.21 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_47000.pt\n",
      "2023-01-10 13:36.21 [info     ] DoubleDQN_online_20230110133544: epoch=47 step=47000 epoch=47 metrics={'time_inference': 0.00011956906318664551, 'time_environment_step': 2.1279573440551758e-05, 'time_sample_batch': 2.9064416885375977e-05, 'time_algorithm_update': 0.0005772643089294434, 'loss': 17.184719046354292, 'time_step': 0.0007622950077056885, 'rollout_return': 8.508341985598317, 'evaluation': 8.514452380851635} step=47000\n",
      "2023-01-10 13:36.22 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_48000.pt\n",
      "2023-01-10 13:36.22 [info     ] DoubleDQN_online_20230110133544: epoch=48 step=48000 epoch=48 metrics={'time_inference': 0.00012039518356323242, 'time_environment_step': 2.190685272216797e-05, 'time_sample_batch': 2.9888153076171875e-05, 'time_algorithm_update': 0.000581834077835083, 'loss': 17.092613276958467, 'time_step': 0.0007694251537322998, 'rollout_return': 7.950498549814383, 'evaluation': 9.932959318183368} step=48000\n",
      "2023-01-10 13:36.22 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_49000.pt\n",
      "2023-01-10 13:36.22 [info     ] DoubleDQN_online_20230110133544: epoch=49 step=49000 epoch=49 metrics={'time_inference': 0.0001209566593170166, 'time_environment_step': 2.1976470947265625e-05, 'time_sample_batch': 2.9947280883789063e-05, 'time_algorithm_update': 0.0005820376873016357, 'loss': 17.515110495328905, 'time_step': 0.0007704925537109375, 'rollout_return': 7.890060641271857, 'evaluation': 11.261335241700433} step=49000\n",
      "2023-01-10 13:36.23 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_50000.pt\n",
      "2023-01-10 13:36.23 [info     ] DoubleDQN_online_20230110133544: epoch=50 step=50000 epoch=50 metrics={'time_inference': 0.00011499929428100586, 'time_environment_step': 2.05080509185791e-05, 'time_sample_batch': 2.665543556213379e-05, 'time_algorithm_update': 0.0005552356243133545, 'loss': 17.305069943666457, 'time_step': 0.0007317781448364258, 'rollout_return': 8.942899359812195, 'evaluation': 10.580261338605734} step=50000\n",
      "2023-01-10 13:36.24 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_51000.pt\n",
      "2023-01-10 13:36.24 [info     ] DoubleDQN_online_20230110133544: epoch=51 step=51000 epoch=51 metrics={'time_inference': 0.00011213374137878417, 'time_environment_step': 1.9867658615112305e-05, 'time_sample_batch': 2.5119543075561522e-05, 'time_algorithm_update': 0.0005462360382080078, 'loss': 17.56674121451378, 'time_step': 0.0007172403335571289, 'rollout_return': 8.78381555358958, 'evaluation': 12.105504759922251} step=51000\n",
      "2023-01-10 13:36.25 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_52000.pt\n",
      "2023-01-10 13:36.25 [info     ] DoubleDQN_online_20230110133544: epoch=52 step=52000 epoch=52 metrics={'time_inference': 0.00011783194541931153, 'time_environment_step': 2.101278305053711e-05, 'time_sample_batch': 2.810359001159668e-05, 'time_algorithm_update': 0.0005644829273223877, 'loss': 17.233162298440934, 'time_step': 0.0007462677955627442, 'rollout_return': 8.380656497641983, 'evaluation': 9.403103893225756} step=52000\n",
      "2023-01-10 13:36.25 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_53000.pt\n",
      "2023-01-10 13:36.25 [info     ] DoubleDQN_online_20230110133544: epoch=53 step=53000 epoch=53 metrics={'time_inference': 0.00011576533317565918, 'time_environment_step': 2.057051658630371e-05, 'time_sample_batch': 2.7192115783691408e-05, 'time_algorithm_update': 0.0005575778484344482, 'loss': 17.626680109739304, 'time_step': 0.0007355437278747559, 'rollout_return': 7.839187396627282, 'evaluation': 8.276692910423751} step=53000\n",
      "2023-01-10 13:36.26 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_54000.pt\n",
      "2023-01-10 13:36.26 [info     ] DoubleDQN_online_20230110133544: epoch=54 step=54000 epoch=54 metrics={'time_inference': 0.00011610913276672364, 'time_environment_step': 2.080798149108887e-05, 'time_sample_batch': 2.8074741363525392e-05, 'time_algorithm_update': 0.0006245238780975342, 'loss': 17.64734617996216, 'time_step': 0.0008041605949401855, 'rollout_return': 8.532257038039536, 'evaluation': 10.097757515480398} step=54000\n",
      "2023-01-10 13:36.27 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_55000.pt\n",
      "2023-01-10 13:36.27 [info     ] DoubleDQN_online_20230110133544: epoch=55 step=55000 epoch=55 metrics={'time_inference': 0.00011130881309509277, 'time_environment_step': 1.9666433334350585e-05, 'time_sample_batch': 2.479887008666992e-05, 'time_algorithm_update': 0.000543682336807251, 'loss': 17.58314015507698, 'time_step': 0.0007133519649505615, 'rollout_return': 8.12942640632298, 'evaluation': 10.659456915808239} step=55000\n",
      "2023-01-10 13:36.28 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_56000.pt\n",
      "2023-01-10 13:36.28 [info     ] DoubleDQN_online_20230110133544: epoch=56 step=56000 epoch=56 metrics={'time_inference': 0.00011731600761413575, 'time_environment_step': 2.1027565002441406e-05, 'time_sample_batch': 2.8394460678100586e-05, 'time_algorithm_update': 0.0005697827339172364, 'loss': 17.626616225004195, 'time_step': 0.0007515144348144531, 'rollout_return': 7.862104328575766, 'evaluation': 6.9178534774893} step=56000\n",
      "2023-01-10 13:36.29 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_57000.pt\n",
      "2023-01-10 13:36.29 [info     ] DoubleDQN_online_20230110133544: epoch=57 step=57000 epoch=57 metrics={'time_inference': 0.00012586569786071777, 'time_environment_step': 2.2727012634277343e-05, 'time_sample_batch': 3.1912803649902345e-05, 'time_algorithm_update': 0.0006224322319030762, 'loss': 17.60945325756073, 'time_step': 0.0008192625045776367, 'rollout_return': 8.83420858756086, 'evaluation': 9.458612579073002} step=57000\n",
      "2023-01-10 13:36.29 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_58000.pt\n",
      "2023-01-10 13:36.29 [info     ] DoubleDQN_online_20230110133544: epoch=58 step=58000 epoch=58 metrics={'time_inference': 0.00012545442581176757, 'time_environment_step': 2.2980451583862305e-05, 'time_sample_batch': 3.1920909881591796e-05, 'time_algorithm_update': 0.0006134331226348877, 'loss': 17.826279842853545, 'time_step': 0.0008101799488067627, 'rollout_return': 8.831304734859163, 'evaluation': 7.569403155477552} step=58000\n",
      "2023-01-10 13:36.30 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_59000.pt\n",
      "2023-01-10 13:36.30 [info     ] DoubleDQN_online_20230110133544: epoch=59 step=59000 epoch=59 metrics={'time_inference': 0.00011573576927185058, 'time_environment_step': 2.0592689514160156e-05, 'time_sample_batch': 2.7366161346435546e-05, 'time_algorithm_update': 0.0005598905086517334, 'loss': 17.761074480295182, 'time_step': 0.0007382030487060547, 'rollout_return': 8.709286510915154, 'evaluation': 6.37650609865654} step=59000\n",
      "2023-01-10 13:36.31 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_60000.pt\n",
      "2023-01-10 13:36.31 [info     ] DoubleDQN_online_20230110133544: epoch=60 step=60000 epoch=60 metrics={'time_inference': 0.00011397266387939453, 'time_environment_step': 2.0056009292602538e-05, 'time_sample_batch': 2.6088953018188476e-05, 'time_algorithm_update': 0.000549910306930542, 'loss': 17.768782925844192, 'time_step': 0.0007242796421051026, 'rollout_return': 8.431331240036469, 'evaluation': 8.847311312902837} step=60000\n",
      "2023-01-10 13:36.32 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_61000.pt\n",
      "2023-01-10 13:36.32 [info     ] DoubleDQN_online_20230110133544: epoch=61 step=61000 epoch=61 metrics={'time_inference': 0.00011521577835083008, 'time_environment_step': 2.050018310546875e-05, 'time_sample_batch': 2.7005910873413086e-05, 'time_algorithm_update': 0.0005603542327880859, 'loss': 17.545542659282685, 'time_step': 0.0007376101016998291, 'rollout_return': 8.307290409716895, 'evaluation': 6.860197343561309} step=61000\n",
      "2023-01-10 13:36.32 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_62000.pt\n",
      "2023-01-10 13:36.32 [info     ] DoubleDQN_online_20230110133544: epoch=62 step=62000 epoch=62 metrics={'time_inference': 0.00011750245094299317, 'time_environment_step': 2.1119117736816406e-05, 'time_sample_batch': 2.870321273803711e-05, 'time_algorithm_update': 0.0005710153579711914, 'loss': 17.695033849000932, 'time_step': 0.0007533624172210694, 'rollout_return': 8.23587762185122, 'evaluation': 8.144283269849172} step=62000\n",
      "2023-01-10 13:36.33 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_63000.pt\n",
      "2023-01-10 13:36.33 [info     ] DoubleDQN_online_20230110133544: epoch=63 step=63000 epoch=63 metrics={'time_inference': 0.00011107897758483887, 'time_environment_step': 1.952815055847168e-05, 'time_sample_batch': 2.442336082458496e-05, 'time_algorithm_update': 0.0005437343120574951, 'loss': 18.032739995479584, 'time_step': 0.0007125496864318848, 'rollout_return': 8.236687482714323, 'evaluation': 9.824000825582093} step=63000\n",
      "2023-01-10 13:36.34 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_64000.pt\n",
      "2023-01-10 13:36.34 [info     ] DoubleDQN_online_20230110133544: epoch=64 step=64000 epoch=64 metrics={'time_inference': 0.00011030054092407227, 'time_environment_step': 1.9510507583618164e-05, 'time_sample_batch': 2.4174928665161134e-05, 'time_algorithm_update': 0.000544595718383789, 'loss': 18.082769780158998, 'time_step': 0.0007123117446899414, 'rollout_return': 7.951786069234011, 'evaluation': 6.786787249468101} step=64000\n",
      "2023-01-10 13:36.35 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_65000.pt\n",
      "2023-01-10 13:36.35 [info     ] DoubleDQN_online_20230110133544: epoch=65 step=65000 epoch=65 metrics={'time_inference': 0.00011076474189758301, 'time_environment_step': 1.943826675415039e-05, 'time_sample_batch': 2.40936279296875e-05, 'time_algorithm_update': 0.0005452103614807128, 'loss': 17.852209028720857, 'time_step': 0.0007133188247680665, 'rollout_return': 7.51806627988451, 'evaluation': 5.889520220593806} step=65000\n",
      "2023-01-10 13:36.35 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_66000.pt\n",
      "2023-01-10 13:36.35 [info     ] DoubleDQN_online_20230110133544: epoch=66 step=66000 epoch=66 metrics={'time_inference': 0.00011066555976867676, 'time_environment_step': 1.9366741180419923e-05, 'time_sample_batch': 2.390766143798828e-05, 'time_algorithm_update': 0.0005430278778076171, 'loss': 17.749637365579606, 'time_step': 0.0007106661796569824, 'rollout_return': 8.39805030142701, 'evaluation': 10.678966159914633} step=66000\n",
      "2023-01-10 13:36.36 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_67000.pt\n",
      "2023-01-10 13:36.36 [info     ] DoubleDQN_online_20230110133544: epoch=67 step=67000 epoch=67 metrics={'time_inference': 0.00011265420913696288, 'time_environment_step': 1.9659757614135743e-05, 'time_sample_batch': 2.4627208709716796e-05, 'time_algorithm_update': 0.0005484778881072998, 'loss': 17.608205918312073, 'time_step': 0.000719327449798584, 'rollout_return': 7.811282223806871, 'evaluation': 7.345583976792716} step=67000\n",
      "2023-01-10 13:36.37 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_68000.pt\n",
      "2023-01-10 13:36.37 [info     ] DoubleDQN_online_20230110133544: epoch=68 step=68000 epoch=68 metrics={'time_inference': 0.00011758875846862792, 'time_environment_step': 2.118706703186035e-05, 'time_sample_batch': 2.852940559387207e-05, 'time_algorithm_update': 0.0005692174434661865, 'loss': 17.409959312438964, 'time_step': 0.0007514865398406983, 'rollout_return': 7.924761797310635, 'evaluation': 12.574206165860355} step=68000\n",
      "2023-01-10 13:36.38 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_69000.pt\n",
      "2023-01-10 13:36.38 [info     ] DoubleDQN_online_20230110133544: epoch=69 step=69000 epoch=69 metrics={'time_inference': 0.00012488532066345215, 'time_environment_step': 2.2552728652954102e-05, 'time_sample_batch': 3.0869483947753906e-05, 'time_algorithm_update': 0.0006096763610839844, 'loss': 17.777255165576936, 'time_step': 0.0008043360710144043, 'rollout_return': 7.848566003557129, 'evaluation': 11.88980075551251} step=69000\n",
      "2023-01-10 13:36.38 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_70000.pt\n",
      "2023-01-10 13:36.38 [info     ] DoubleDQN_online_20230110133544: epoch=70 step=70000 epoch=70 metrics={'time_inference': 0.00011108684539794922, 'time_environment_step': 1.9526958465576172e-05, 'time_sample_batch': 2.4385929107666015e-05, 'time_algorithm_update': 0.0005456984043121337, 'loss': 18.185127311706545, 'time_step': 0.0007144646644592285, 'rollout_return': 8.65595745732783, 'evaluation': 6.8556215406667445} step=70000\n",
      "2023-01-10 13:36.39 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_71000.pt\n",
      "2023-01-10 13:36.39 [info     ] DoubleDQN_online_20230110133544: epoch=71 step=71000 epoch=71 metrics={'time_inference': 0.0001167306900024414, 'time_environment_step': 2.081441879272461e-05, 'time_sample_batch': 2.7880430221557616e-05, 'time_algorithm_update': 0.0005631628036499023, 'loss': 18.03983269071579, 'time_step': 0.0007433912754058838, 'rollout_return': 9.679123713069997, 'evaluation': 10.048887628621753} step=71000\n",
      "2023-01-10 13:36.40 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_72000.pt\n",
      "2023-01-10 13:36.40 [info     ] DoubleDQN_online_20230110133544: epoch=72 step=72000 epoch=72 metrics={'time_inference': 0.0001141805648803711, 'time_environment_step': 2.031135559082031e-05, 'time_sample_batch': 2.6583433151245116e-05, 'time_algorithm_update': 0.0005555903911590576, 'loss': 17.862127138376238, 'time_step': 0.0007309496402740478, 'rollout_return': 7.632728350938327, 'evaluation': 6.839023523154447} step=72000\n",
      "2023-01-10 13:36.41 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_73000.pt\n",
      "2023-01-10 13:36.41 [info     ] DoubleDQN_online_20230110133544: epoch=73 step=73000 epoch=73 metrics={'time_inference': 0.00011073088645935059, 'time_environment_step': 1.9548416137695314e-05, 'time_sample_batch': 2.4799108505249024e-05, 'time_algorithm_update': 0.0005463352203369141, 'loss': 18.018476453065873, 'time_step': 0.0007152140140533447, 'rollout_return': 8.081572452604236, 'evaluation': 12.609401332204248} step=73000\n",
      "2023-01-10 13:36.41 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_74000.pt\n",
      "2023-01-10 13:36.41 [info     ] DoubleDQN_online_20230110133544: epoch=74 step=74000 epoch=74 metrics={'time_inference': 0.00011804628372192383, 'time_environment_step': 2.1193742752075195e-05, 'time_sample_batch': 2.8827428817749024e-05, 'time_algorithm_update': 0.0005700221061706543, 'loss': 18.11789040708542, 'time_step': 0.0007532429695129394, 'rollout_return': 9.113294460247936, 'evaluation': 9.521278253843068} step=74000\n",
      "2023-01-10 13:36.42 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_75000.pt\n",
      "2023-01-10 13:36.42 [info     ] DoubleDQN_online_20230110133544: epoch=75 step=75000 epoch=75 metrics={'time_inference': 0.00011591243743896485, 'time_environment_step': 2.056717872619629e-05, 'time_sample_batch': 2.7837514877319336e-05, 'time_algorithm_update': 0.0005620203018188477, 'loss': 18.297867792606354, 'time_step': 0.0007410073280334473, 'rollout_return': 8.97284458698643, 'evaluation': 10.129775010325876} step=75000\n",
      "2023-01-10 13:36.43 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_76000.pt\n",
      "2023-01-10 13:36.43 [info     ] DoubleDQN_online_20230110133544: epoch=76 step=76000 epoch=76 metrics={'time_inference': 0.00011209964752197266, 'time_environment_step': 1.9710540771484374e-05, 'time_sample_batch': 2.5690317153930664e-05, 'time_algorithm_update': 0.0005462875366210937, 'loss': 18.13838420009613, 'time_step': 0.000717714786529541, 'rollout_return': 7.416938601682587, 'evaluation': 12.275917645017838} step=76000\n",
      "2023-01-10 13:36.44 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_77000.pt\n",
      "2023-01-10 13:36.44 [info     ] DoubleDQN_online_20230110133544: epoch=77 step=77000 epoch=77 metrics={'time_inference': 0.00011462783813476562, 'time_environment_step': 2.0311832427978516e-05, 'time_sample_batch': 2.6584386825561523e-05, 'time_algorithm_update': 0.0005558793544769287, 'loss': 18.221529966831206, 'time_step': 0.0007318320274353027, 'rollout_return': 8.176187275936421, 'evaluation': 11.944339635347507} step=77000\n",
      "2023-01-10 13:36.44 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_78000.pt\n",
      "2023-01-10 13:36.44 [info     ] DoubleDQN_online_20230110133544: epoch=78 step=78000 epoch=78 metrics={'time_inference': 0.00011068224906921387, 'time_environment_step': 1.9420862197875975e-05, 'time_sample_batch': 2.420759201049805e-05, 'time_algorithm_update': 0.0005438325405120849, 'loss': 18.446222841262816, 'time_step': 0.0007118275165557862, 'rollout_return': 8.789430898247545, 'evaluation': 8.837828487170261} step=78000\n",
      "2023-01-10 13:36.45 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_79000.pt\n",
      "2023-01-10 13:36.45 [info     ] DoubleDQN_online_20230110133544: epoch=79 step=79000 epoch=79 metrics={'time_inference': 0.00011425161361694336, 'time_environment_step': 2.0220756530761718e-05, 'time_sample_batch': 2.6581048965454103e-05, 'time_algorithm_update': 0.0005577836036682129, 'loss': 18.22664479494095, 'time_step': 0.0007332713603973389, 'rollout_return': 8.69183227266574, 'evaluation': 12.7887958657677} step=79000\n",
      "2023-01-10 13:36.46 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_80000.pt\n",
      "2023-01-10 13:36.46 [info     ] DoubleDQN_online_20230110133544: epoch=80 step=80000 epoch=80 metrics={'time_inference': 0.00012102365493774414, 'time_environment_step': 2.2066116333007814e-05, 'time_sample_batch': 3.012824058532715e-05, 'time_algorithm_update': 0.000583719253540039, 'loss': 18.42094929933548, 'time_step': 0.0007725110054016114, 'rollout_return': 8.809471445112955, 'evaluation': 8.640335900308333} step=80000\n",
      "2023-01-10 13:36.47 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_81000.pt\n",
      "2023-01-10 13:36.47 [info     ] DoubleDQN_online_20230110133544: epoch=81 step=81000 epoch=81 metrics={'time_inference': 0.00012445878982543946, 'time_environment_step': 2.234196662902832e-05, 'time_sample_batch': 3.171539306640625e-05, 'time_algorithm_update': 0.0005938611030578613, 'loss': 18.396356867074967, 'time_step': 0.0007882678508758545, 'rollout_return': 8.885847640888052, 'evaluation': 12.893833750101965} step=81000\n",
      "2023-01-10 13:36.48 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_82000.pt\n",
      "2023-01-10 13:36.48 [info     ] DoubleDQN_online_20230110133544: epoch=82 step=82000 epoch=82 metrics={'time_inference': 0.0001262032985687256, 'time_environment_step': 2.3146629333496095e-05, 'time_sample_batch': 3.17234992980957e-05, 'time_algorithm_update': 0.0006002700328826905, 'loss': 18.7517559261322, 'time_step': 0.0007979159355163575, 'rollout_return': 8.949807436427937, 'evaluation': 8.204044275339061} step=82000\n",
      "2023-01-10 13:36.48 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_83000.pt\n",
      "2023-01-10 13:36.48 [info     ] DoubleDQN_online_20230110133544: epoch=83 step=83000 epoch=83 metrics={'time_inference': 0.00012061119079589844, 'time_environment_step': 2.166914939880371e-05, 'time_sample_batch': 2.997899055480957e-05, 'time_algorithm_update': 0.0005767107009887696, 'loss': 18.706561599135398, 'time_step': 0.0007642788887023926, 'rollout_return': 8.712889267258435, 'evaluation': 11.154650005689387} step=83000\n",
      "2023-01-10 13:36.49 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_84000.pt\n",
      "2023-01-10 13:36.49 [info     ] DoubleDQN_online_20230110133544: epoch=84 step=84000 epoch=84 metrics={'time_inference': 0.00011736059188842773, 'time_environment_step': 2.0911455154418946e-05, 'time_sample_batch': 2.8370141983032225e-05, 'time_algorithm_update': 0.000566356897354126, 'loss': 18.15817356491089, 'time_step': 0.0007479960918426513, 'rollout_return': 8.47083362910423, 'evaluation': 10.220772539203978} step=84000\n",
      "2023-01-10 13:36.50 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_85000.pt\n",
      "2023-01-10 13:36.50 [info     ] DoubleDQN_online_20230110133544: epoch=85 step=85000 epoch=85 metrics={'time_inference': 0.00012070822715759277, 'time_environment_step': 2.1203041076660157e-05, 'time_sample_batch': 2.8691291809082032e-05, 'time_algorithm_update': 0.0005894379615783692, 'loss': 18.50357844877243, 'time_step': 0.0007757000923156738, 'rollout_return': 8.84396500171482, 'evaluation': 6.519204707310846} step=85000\n",
      "2023-01-10 13:36.51 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_86000.pt\n",
      "2023-01-10 13:36.51 [info     ] DoubleDQN_online_20230110133544: epoch=86 step=86000 epoch=86 metrics={'time_inference': 0.00011570906639099121, 'time_environment_step': 2.0670175552368165e-05, 'time_sample_batch': 2.732682228088379e-05, 'time_algorithm_update': 0.0005624675750732422, 'loss': 18.50662155628204, 'time_step': 0.0007407784461975098, 'rollout_return': 8.430411955859757, 'evaluation': 10.79365351639645} step=86000\n",
      "2023-01-10 13:36.51 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_87000.pt\n",
      "2023-01-10 13:36.51 [info     ] DoubleDQN_online_20230110133544: epoch=87 step=87000 epoch=87 metrics={'time_inference': 0.00011148715019226074, 'time_environment_step': 1.9703149795532228e-05, 'time_sample_batch': 2.4446964263916015e-05, 'time_algorithm_update': 0.0005464096069335937, 'loss': 18.129820897579194, 'time_step': 0.0007158777713775635, 'rollout_return': 8.369860583164836, 'evaluation': 11.00929655290463} step=87000\n",
      "2023-01-10 13:36.52 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_88000.pt\n",
      "2023-01-10 13:36.52 [info     ] DoubleDQN_online_20230110133544: epoch=88 step=88000 epoch=88 metrics={'time_inference': 0.00011312580108642578, 'time_environment_step': 2.00345516204834e-05, 'time_sample_batch': 2.5778770446777343e-05, 'time_algorithm_update': 0.0005526261329650879, 'loss': 18.490315305948258, 'time_step': 0.0007256865501403809, 'rollout_return': 9.222943444021993, 'evaluation': 10.514724893302677} step=88000\n",
      "2023-01-10 13:36.53 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_89000.pt\n",
      "2023-01-10 13:36.53 [info     ] DoubleDQN_online_20230110133544: epoch=89 step=89000 epoch=89 metrics={'time_inference': 0.00011492037773132325, 'time_environment_step': 2.03244686126709e-05, 'time_sample_batch': 2.666926383972168e-05, 'time_algorithm_update': 0.0005566878318786621, 'loss': 18.551903820991516, 'time_step': 0.0007328417301177978, 'rollout_return': 8.363236196260704, 'evaluation': 11.94612108742496} step=89000\n",
      "2023-01-10 13:36.54 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_90000.pt\n",
      "2023-01-10 13:36.54 [info     ] DoubleDQN_online_20230110133544: epoch=90 step=90000 epoch=90 metrics={'time_inference': 0.0001169748306274414, 'time_environment_step': 2.089667320251465e-05, 'time_sample_batch': 2.813601493835449e-05, 'time_algorithm_update': 0.0005678689479827881, 'loss': 18.491344033956526, 'time_step': 0.0007487077713012695, 'rollout_return': 8.631743241093771, 'evaluation': 5.872311642727319} step=90000\n",
      "2023-01-10 13:36.54 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_91000.pt\n",
      "2023-01-10 13:36.54 [info     ] DoubleDQN_online_20230110133544: epoch=91 step=91000 epoch=91 metrics={'time_inference': 0.00011881279945373535, 'time_environment_step': 2.1399736404418947e-05, 'time_sample_batch': 2.9352903366088866e-05, 'time_algorithm_update': 0.0005664896965026856, 'loss': 18.631987858772277, 'time_step': 0.0007512674331665039, 'rollout_return': 7.772097849520215, 'evaluation': 11.039782353352223} step=91000\n",
      "2023-01-10 13:36.55 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_92000.pt\n",
      "2023-01-10 13:36.55 [info     ] DoubleDQN_online_20230110133544: epoch=92 step=92000 epoch=92 metrics={'time_inference': 0.00011650609970092773, 'time_environment_step': 2.0740747451782225e-05, 'time_sample_batch': 2.8027772903442383e-05, 'time_algorithm_update': 0.0005625209808349609, 'loss': 18.49208261728287, 'time_step': 0.0007425591945648193, 'rollout_return': 8.479748155937335, 'evaluation': 9.491261998328518} step=92000\n",
      "2023-01-10 13:36.56 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_93000.pt\n",
      "2023-01-10 13:36.56 [info     ] DoubleDQN_online_20230110133544: epoch=93 step=93000 epoch=93 metrics={'time_inference': 0.0001147768497467041, 'time_environment_step': 2.0451784133911134e-05, 'time_sample_batch': 2.7228355407714842e-05, 'time_algorithm_update': 0.0005614333152770996, 'loss': 18.677561992168428, 'time_step': 0.0007384474277496338, 'rollout_return': 9.26246013502016, 'evaluation': 10.790627225166237} step=93000\n",
      "2023-01-10 13:36.57 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_94000.pt\n",
      "2023-01-10 13:36.57 [info     ] DoubleDQN_online_20230110133544: epoch=94 step=94000 epoch=94 metrics={'time_inference': 0.00012123942375183105, 'time_environment_step': 2.1959543228149415e-05, 'time_sample_batch': 2.812528610229492e-05, 'time_algorithm_update': 0.0006087543964385986, 'loss': 18.906161060094835, 'time_step': 0.0007956759929656982, 'rollout_return': 7.616622887602133, 'evaluation': 9.395810550151229} step=94000\n",
      "2023-01-10 13:36.58 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_95000.pt\n",
      "2023-01-10 13:36.58 [info     ] DoubleDQN_online_20230110133544: epoch=95 step=95000 epoch=95 metrics={'time_inference': 0.00011214232444763183, 'time_environment_step': 1.9775152206420898e-05, 'time_sample_batch': 2.5204896926879883e-05, 'time_algorithm_update': 0.0005523612499237061, 'loss': 18.486158798575403, 'time_step': 0.0007235558032989502, 'rollout_return': 8.487555105443299, 'evaluation': 10.884676673542028} step=95000\n",
      "2023-01-10 13:36.58 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_96000.pt\n",
      "2023-01-10 13:36.58 [info     ] DoubleDQN_online_20230110133544: epoch=96 step=96000 epoch=96 metrics={'time_inference': 0.00011129403114318847, 'time_environment_step': 1.9569635391235352e-05, 'time_sample_batch': 2.451014518737793e-05, 'time_algorithm_update': 0.0005441999435424805, 'loss': 18.615053426623344, 'time_step': 0.000713343620300293, 'rollout_return': 8.004187241485093, 'evaluation': 9.32375150283355} step=96000\n",
      "2023-01-10 13:36.59 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_97000.pt\n",
      "2023-01-10 13:36.59 [info     ] DoubleDQN_online_20230110133544: epoch=97 step=97000 epoch=97 metrics={'time_inference': 0.00011813688278198242, 'time_environment_step': 2.1093130111694337e-05, 'time_sample_batch': 2.778339385986328e-05, 'time_algorithm_update': 0.0005753405094146728, 'loss': 18.673325817346573, 'time_step': 0.0007573084831237793, 'rollout_return': 8.001973444961266, 'evaluation': 10.190628701099424} step=97000\n",
      "2023-01-10 13:37.00 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_98000.pt\n",
      "2023-01-10 13:37.00 [info     ] DoubleDQN_online_20230110133544: epoch=98 step=98000 epoch=98 metrics={'time_inference': 0.00012198829650878906, 'time_environment_step': 2.2235393524169922e-05, 'time_sample_batch': 3.092789649963379e-05, 'time_algorithm_update': 0.0005834290981292725, 'loss': 18.643261256217958, 'time_step': 0.0007744972705841064, 'rollout_return': 8.661545238144496, 'evaluation': 12.451457369817449} step=98000\n",
      "2023-01-10 13:37.01 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_99000.pt\n",
      "2023-01-10 13:37.01 [info     ] DoubleDQN_online_20230110133544: epoch=99 step=99000 epoch=99 metrics={'time_inference': 0.00011878228187561035, 'time_environment_step': 2.1347761154174805e-05, 'time_sample_batch': 2.9495716094970703e-05, 'time_algorithm_update': 0.0005719711780548096, 'loss': 18.684900034427642, 'time_step': 0.0007568659782409668, 'rollout_return': 8.582019837363971, 'evaluation': 10.099706231396599} step=99000\n",
      "2023-01-10 13:37.01 [info     ] Model parameters are saved to d3rlpy_logs/DoubleDQN_online_20230110133544/model_100000.pt\n",
      "2023-01-10 13:37.01 [info     ] DoubleDQN_online_20230110133544: epoch=100 step=100000 epoch=100 metrics={'time_inference': 0.00011378097534179688, 'time_environment_step': 1.9981861114501954e-05, 'time_sample_batch': 2.575230598449707e-05, 'time_algorithm_update': 0.0005571599006652832, 'loss': 18.45300179553032, 'time_step': 0.0007309808731079102, 'rollout_return': 8.14166268087276, 'evaluation': 9.939543710844987} step=100000\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "# skip if there is a pre-trained model\n",
    "ddqn.fit_online(\n",
    "    env_,\n",
    "    buffer,\n",
    "    explorer=explorer,\n",
    "    eval_env=env_,\n",
    "    n_steps=100000,\n",
    "    n_steps_per_epoch=1000,\n",
    "    update_start_step=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "ddqn.save_model(\"d3rlpy_logs/ddqn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-10 13:37.01 [warning  ] Parameters will be reinitialized.\n"
     ]
    }
   ],
   "source": [
    "# reload model\n",
    "ddqn.build_with_env(env)\n",
    "ddqn.load_model(\"d3rlpy_logs/ddqn.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Epsilon-Greedy behavior policy\n",
    "\n",
    "Let's now convert the deterministic policy (i.e., ddqn policy) into a stochastic behavior policy.\n",
    "\n",
    "We use epsilon-greedy policy to collect logged data using `DiscreteEpsilonGreedyHead`, where the behavior policy greedily takes an action chosen by the deterministic policy with probability $1 - \\epsilon$ and takes an action randomly with probability $\\epsilon$.\n",
    "\n",
    "Note that, `SyntheticDataset` has the following arguments:\n",
    "- `env`: REC environment for RL defined in the previous section.\n",
    "- `behavior_policy`: RL agent (or algorithm) used for the data collection.\n",
    "- `maximum_step_per_episode`: Maximum number of timesteps in an episode.\n",
    "- `random_state`: Random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the base ddqn policy into a stochastic data collection policy\n",
    "from ofrl.policy import DiscreteEpsilonGreedyHead\n",
    "\n",
    "behavior_policy = DiscreteEpsilonGreedyHead(\n",
    "    ddqn, \n",
    "    n_actions=env.action_space.n,\n",
    "    epsilon=0.3,  # probability of taking random action\n",
    "    name=\"ddqn_epsilon_0.3\",\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d989bbc36c8c46a993fe49a13aa468d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_trajectories]:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# collect data\n",
    "dataset = SyntheticDataset(\n",
    "    env=env,\n",
    "    behavior_policy=behavior_policy,\n",
    "    max_episode_steps=env.step_per_episode,\n",
    "    random_state=random_state,\n",
    ")\n",
    "logged_dataset = dataset.obtain_episodes(n_trajectories=10000, obtain_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': 100000,\n",
       " 'n_trajectories': 10000,\n",
       " 'step_per_trajectory': 10,\n",
       " 'action_type': 'discrete',\n",
       " 'n_actions': 99,\n",
       " 'action_dim': None,\n",
       " 'action_meaning': None,\n",
       " 'action_keys': None,\n",
       " 'state_dim': 5,\n",
       " 'state_keys': None,\n",
       " 'state': array([[ 0.38925464, -0.46301775,  0.68943702, -0.28074372, -0.46483856],\n",
       "        [ 0.37289622, -0.54751399,  0.73193904,  0.02358127, -0.15775301],\n",
       "        [ 0.33788017, -0.44968735,  0.63230349, -0.26136228, -0.46422013],\n",
       "        ...,\n",
       "        [ 0.56867301, -0.74462813, -0.06409205,  0.10620445, -0.32673045],\n",
       "        [ 0.65290953, -0.7024288 , -0.0708965 , -0.11297017, -0.2500287 ],\n",
       "        [ 0.56867301, -0.74462813, -0.06409205,  0.10620445, -0.32673045]]),\n",
       " 'action': array([72,  1, 72, ..., 37, 68, 16]),\n",
       " 'reward': array([1.33387383, 0.08952685, 1.33387383, ..., 1.1252607 , 1.28476678,\n",
       "        1.65073247]),\n",
       " 'done': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'terminal': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'info': {},\n",
       " 'pscore': array([0.7030303, 0.0030303, 0.7030303, ..., 0.0030303, 0.7030303,\n",
       "        0.0030303])}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Softmax behavior policy\n",
    "We can also use `DiscreteSoftmaxHead` to derive a stochastic behavior policy.\n",
    "\n",
    "This algorithm uses Q function of the original algorithm, which estimates the value of a given context and action pair (i.e., $(s, a)$) as $Q(s, a)$. \\\n",
    "Specifically, the behavior policy chooses actions stochastically as $\\pi(a \\mid s) = \\frac{\\exp(Q(s, a) / \\tau)}{\\sum_{a' \\in A} \\exp(Q(s, a') / \\tau)}$, where $A$ indicates the set discrete actions and $\\tau$ is an inverse temperature parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert base ddqn policy into a stochastic data collection policy\n",
    "from ofrl.policy import DiscreteSoftmaxHead\n",
    "\n",
    "behavior_policy = DiscreteSoftmaxHead(\n",
    "    ddqn, \n",
    "    n_actions=env.action_space.n,\n",
    "    tau=1.0,  # temperature parameter\n",
    "    name=\"ddqn_softmax_tau_1.0\",\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bdee7256e034f2ba55d1341f5a0ebb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[obtain_trajectories]:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# collect data\n",
    "dataset = SyntheticDataset(\n",
    "    env=env,\n",
    "    behavior_policy=behavior_policy,\n",
    "    max_episode_steps=env.step_per_episode,\n",
    "    random_state=random_state,\n",
    ")\n",
    "logged_dataset = dataset.obtain_episodes(n_trajectories=10000, obtain_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': 100000,\n",
       " 'n_trajectories': 10000,\n",
       " 'step_per_trajectory': 10,\n",
       " 'action_type': 'discrete',\n",
       " 'n_actions': 99,\n",
       " 'action_dim': None,\n",
       " 'action_meaning': None,\n",
       " 'action_keys': None,\n",
       " 'state_dim': 5,\n",
       " 'state_keys': None,\n",
       " 'state': array([[ 0.47956029, -0.29495206,  0.40005482, -0.92594096, -0.8006856 ],\n",
       "        [ 0.44717416, -0.40422194,  0.30808829, -0.43678018, -0.59240575],\n",
       "        [ 0.44717416, -0.40422194,  0.30808829, -0.43678018, -0.59240575],\n",
       "        ...,\n",
       "        [ 0.27387907,  0.50964269, -0.56166299,  0.49044502, -0.33053434],\n",
       "        [ 0.27387907,  0.50964269, -0.56166299,  0.49044502, -0.33053434],\n",
       "        [ 0.27387907,  0.50964269, -0.56166299,  0.49044502, -0.33053434]]),\n",
       " 'action': array([68, 68, 72, ..., 30, 30, 30]),\n",
       " 'reward': array([0.67500556, 0.67500556, 0.87888813, ..., 1.41518321, 1.41518321,\n",
       "        1.41518321]),\n",
       " 'done': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'terminal': array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " 'info': {},\n",
       " 'pscore': array([0.34823674, 0.41150126, 0.51696187, ..., 0.98608762, 0.98608762,\n",
       "        0.98608762])}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For offline RL and OPE procedures, please refer to [examples/quickstart/REC_synthetic_discrete_basic.ipynb](https://github.com/negocia-inc/REC_reinforcement_learing/blob/master/examples/quickstart/REC_synthetic_discrete_basic.ipynb).\n",
    "\n",
    "For more advanced topic in OPE and OPS, please refer to [examples/quickstart/REC_synthetic_discrete_advanced.ipynb](https://github.com/negocia-inc/REC_reinforcement_learing/blob/ope/examples/quickstart/REC_synthetic_discrete_advanced.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- Yuta Saito, Shunsuke Aihara, Megumi Matsutani, and Yusuke Narita. \\\n",
    "\"Open Bandit Dataset and Pipeline: Towards Realistic and Reproducible Off-Policy Evaluation.\", 2021.\n",
    "\n",
    "- Takuma Seno and Michita Imai. \\\n",
    "\"d3rlpy: An Offline Deep Reinforcement Library.\", 2021.\n",
    "\n",
    "- Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine. \\\n",
    "\"Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor.\" 2018.\n",
    "\n",
    "- Di Wu, Xiujun Chen, Xun Yang, Hao Wang, Qing Tan, Xiaoxun Zhang, Jian Xu, and Kun Gai. \\\n",
    "\"Budget Constrained Bidding by Model-free Reinforcement Learning in Display Advertising.\", 2018.\n",
    "\n",
    "- Jun Zhao, Guang Qiu, Ziyu Guan, Wei Zhao, and Xiaofei He. \\\n",
    "\"Deep Reinforcement Learning for Sponsored Search Real-time Bidding.\", 2018.\n",
    "\n",
    "- Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. \\\n",
    "\"OpenAI Gym.\", 2016.\n",
    "\n",
    "- Hado van Hasselt, Arthur Guez, and David Silver. \\\n",
    "\"Deep Reinforcement Learning with Double Q-learning.\", 2015."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('3.10.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Sep 10 2022, 14:58:52) [Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "70404ee114725fce8ed9e697d67827f8546c678889944e6d695790702cbfe1f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
